{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "gSMt7chaJC8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "thp1U_XZApw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ae57ef-a2a7-4153-b2cd-6797c2375c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "2NzbWCTqKcZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n1UX_n3N-nqt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import spacy\n",
        "import numpy as np\n",
        "import json,time\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creates a torch.device object that represents the device (GPU or CPU) on which the computation will be executed.\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available()\n",
        "                      else 'cpu')"
      ],
      "metadata": {
        "id": "IDPDMppiKn8k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT-base-uncased model and tokenizer\n",
        "\n",
        "model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8).to(device)\n",
        "# model = transformers.BertForQuestionAnswering.from_pretrained('bert-base-uncased', num_labels=8).to(device)\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "ZhNLLp6DKkTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "760be2a9ecf44bc7b6365e7ce9975bd4",
            "8f581af61cb7426795b8eea5b260a784",
            "963eb22ee09042199c260ef4b0f48e60",
            "b7b5ce6010d74d05bef38422e2b1b70a",
            "0486528000f54b8c8443ce2e93bd975f",
            "0c35da0eafd746839e08a5b0b3ac8931",
            "5cd08d79b82f46e8b39c255c270cc2b7",
            "5c47383bc49743ceb2e176ccbcee4743",
            "71a1420175ec4df4bcfe87b300083701",
            "1b1e42f2d0ee469eb3e4efc752bfeb17",
            "759366c0c05d44ab88c42bde7dd735dc",
            "3d7a38e96ddc418a8421dbe88a3ab824",
            "cb433871d0084166aace3b9685223c13",
            "1436916ecc294d4fb92f523e78802f1d",
            "6381750f0a014a6698a78d6cd9a711bb",
            "ba09a27a2ccf4cf097601ae469707533",
            "882e72ca596b429aab6be377ce3b297a",
            "7c5ebaac663e43aa9a2dd01ce9bc7134",
            "f6934d6a00554165bce353dbc07c9d70",
            "c1efc6ca7c954007801b31948fa62757",
            "0887256920d04d058fc1bce184b0e93e",
            "86fa42e6f985445ea5e41cabc0aae115",
            "278bdbef2ae64e028351f2c61c5dd7f0",
            "b0b31f7474c942e7bc98ddc342afdeee",
            "16df24f7f5484706b95fe4fe32ec3660",
            "d3afa539e73f4b14b2cd5b0d15d818a2",
            "84503ea4f07f4695a8069ca5f3ec088e",
            "e6d9650b34ae4c9593e6f8d381fad262",
            "c568e90e4de54541aebdc374ad9d4f83",
            "351e86ff07b342968725182be74563e3",
            "daf3096737614cb3995dea395aaf2c01",
            "dcfc2545dced46c3b4e821ff8c0b29b9",
            "191bf5f5ac7d4868afd19173072fb1b2",
            "0046c4a1d7ef44c68db074d889e5bf9f",
            "8e0c3245c7fe4775bdd4ea27c9a1e8e9",
            "2cc43f42fc5b4bffb91b575737808269",
            "f09aa5759931431e9bf067dda82a36a4",
            "fad86784d5974c458fc28c33c892154b",
            "81c59b0c869d459a98c4b6a292b7f29c",
            "946ebdd31d7d4607bc8ef4e6e2f4dfd0",
            "222f16dd891a4d139aab0908bdb9b80c",
            "45368e31d10542bfbe0fa08c6bc02481",
            "544a2794ed5d4b438425b1d62dcb7b56",
            "31155667eb05426889aada48c1206fe9"
          ]
        },
        "outputId": "3c091a75-dfca-4222-e401-2c4063f27a93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "760be2a9ecf44bc7b6365e7ce9975bd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d7a38e96ddc418a8421dbe88a3ab824"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "278bdbef2ae64e028351f2c61c5dd7f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0046c4a1d7ef44c68db074d889e5bf9f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading SquadV2 Dataset"
      ],
      "metadata": {
        "id": "DxFocIzuMNIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "# Load SQuAD v2 dataset and preprocess data\n",
        "\n",
        "!mkdir squadV2_ds\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squadV2_ds/train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squadV2_ds/dev-v2.0.json"
      ],
      "metadata": {
        "id": "trU8HYFuMMjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cee6e7-3291-4977-8b85-baf411d72712"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-07 10:09:53--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘squadV2_ds/train-v2.0.json’\n",
            "\n",
            "squadV2_ds/train-v2 100%[===================>]  40.17M   177MB/s    in 0.2s    \n",
            "\n",
            "2023-03-07 10:09:54 (177 MB/s) - ‘squadV2_ds/train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2023-03-07 10:09:54--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘squadV2_ds/dev-v2.0.json’\n",
            "\n",
            "squadV2_ds/dev-v2.0 100%[===================>]   4.17M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-03-07 10:09:54 (51.7 MB/s) - ‘squadV2_ds/dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve and Store the data"
      ],
      "metadata": {
        "id": "dXIkts02Mh3D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vYGktSz0B_t7"
      },
      "outputs": [],
      "source": [
        "# Give the path for train data\n",
        "path = Path('/content/squadV2_ds/train-v2.0.json')\n",
        "\n",
        "# Open .json file\n",
        "with open(path, 'rb') as f:\n",
        "    squad_dict = json.load(f)\n",
        "\n",
        "texts = []\n",
        "queries = []\n",
        "answers = []\n",
        "\n",
        "# Search for each passage, its question and its answer\n",
        "for group in squad_dict['data']:\n",
        "    for passage in group['paragraphs']:\n",
        "        context = passage['context']\n",
        "        for qa in passage['qas']:\n",
        "            question = qa['question']\n",
        "            for answer in qa['answers']:\n",
        "                # Store every passage, query and its answer to the lists\n",
        "                texts.append(context)\n",
        "                queries.append(question)\n",
        "                answers.append(answer['text'])\n",
        "\n",
        "passages_train, questions_train, answers_train = texts, queries, answers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Give the path for train data\n",
        "path = Path('/content/squadV2_ds/dev-v2.0.json')\n",
        "\n",
        "# Open .json file\n",
        "with open(path, 'rb') as f:\n",
        "    squad_dict = json.load(f)\n",
        "\n",
        "texts = []\n",
        "queries = []\n",
        "answers = []\n",
        "\n",
        "# Search for each passage, its question and its answer\n",
        "for group in squad_dict['data']:\n",
        "    for passage in group['paragraphs']:\n",
        "        context = passage['context']\n",
        "        for qa in passage['qas']:\n",
        "            question = qa['question']\n",
        "            for answer in qa['answers']:\n",
        "                # Store every passage, query and its answer to the lists\n",
        "                texts.append(context)\n",
        "                queries.append(question)\n",
        "                answers.append(answer['text'])\n",
        "\n",
        "passages_val, questions_val, answers_val = texts, queries, answers"
      ],
      "metadata": {
        "id": "sO_4TD_Cd49g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S8hSTlpUDUb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf89a1b5-7201-4a0f-c2a3-c29f798a08a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86821\n",
            "86821\n",
            "86821\n",
            "Passage:  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
            "Query:  When did Beyonce start becoming popular?\n",
            "Answer:  in the late 1990s\n"
          ]
        }
      ],
      "source": [
        "# passages = passages[:1000]\n",
        "# questions = questions[:1000]\n",
        "# answers = answers[:1000]\n",
        "print(len(passages_train))\n",
        "print(len(questions_train))\n",
        "print(len(answers_train))\n",
        "\n",
        "print(\"Passage: \",passages_train[0])  \n",
        "print(\"Query: \",questions_train[0])\n",
        "print(\"Answer: \",answers_train[0])\n",
        "\n",
        "# print(questions[0].split(\" \", 1)[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# passages = passages[:1000]\n",
        "# questions = questions[:1000]\n",
        "# answers = answers[:1000]\n",
        "print(len(passages_val))\n",
        "print(len(questions_val))\n",
        "print(len(answers_val))\n",
        "\n",
        "print(\"Passage: \",passages_val[0])  \n",
        "print(\"Query: \",questions_val[0])\n",
        "print(\"Answer: \",answers_val[0])\n",
        "\n",
        "# print(questions[0].split(\" \", 1)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1CJ3FcHe6kQ",
        "outputId": "db19623d-0237-49f1-9a9f-8b67a647a528"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20302\n",
            "20302\n",
            "20302\n",
            "Passage:  The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
            "Query:  In what country is Normandy located?\n",
            "Answer:  France\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ro5hrtL_PUdL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h_j00f5o-9Ri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02114979-8a0e-4ce7-8451-e73299163213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "# training data tokenization\n",
        "\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# iterates through pairs of passages and answers and calls tokenizer.encode_plus() on each pair.\n",
        "# tokenizes a piece of text(passages, answers) and returns a dictionary containing various pieces of information about the tokens.\n",
        "''' \n",
        "  the resulting dictionary contains two keys: input_ids and attention_mask. \n",
        "  input_ids is a tensor that contains the token IDs of the input sequence,\n",
        "  and attention_mask is a tensor that contains a binary mask indicating which tokens are padding and which ones are not.\n",
        "'''\n",
        "for passage, answer in zip(passages_train, answers_train):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        answer,\n",
        "                        passage,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 512,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "    attention_masks_train.append(encoded_dict['attention_mask'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation data tokenization\n",
        "\n",
        "\n",
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "for passage, answer in zip(passages_val, answers_val):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        answer,\n",
        "                        passage,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 512,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K-E7WH_fMP6",
        "outputId": "dbc7d398-2fa5-464d-cf9a-7f2a7ec771a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entity Name Recognition"
      ],
      "metadata": {
        "id": "9zmJ1QidRsnc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Kq1Uxk31IfaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c1bf86-a2c7-4a6c-8d9a-355a0bd5afac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 86821/86821 [09:31<00:00, 151.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label     :   frequance\n",
            "CARDINAL   :   8368\n",
            "DATE   :   9959\n",
            "EVENT   :   308\n",
            "FAC   :   326\n",
            "GPE   :   5792\n",
            "LANGUAGE   :   235\n",
            "LAW   :   121\n",
            "LOC   :   711\n",
            "MONEY   :   814\n",
            "NORP   :   3390\n",
            "ORDINAL   :   744\n",
            "ORG   :   10792\n",
            "PERCENT   :   1312\n",
            "PERSON   :   7732\n",
            "PRODUCT   :   383\n",
            "QUANTITY   :   439\n",
            "TIME   :   216\n",
            "WORK_OF_ART   :   242\n",
            "None    :   34937\n"
          ]
        }
      ],
      "source": [
        "# Obtain entity type of answer using spaCy and create learnable embedding\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "entity_types = []\n",
        "for answer in tqdm(answers_train):\n",
        "    doc = nlp(answer)\n",
        "    if doc.ents:\n",
        "        entity_types.append(doc.ents[0].label_)\n",
        "    else:\n",
        "        entity_types.append('None')\n",
        "\n",
        "\n",
        "# printing frequancy of each label in dataset\n",
        "print('label     :   frequance')\n",
        "for label in nlp.get_pipe(\"ner\").labels:\n",
        "  print(label,\"  :  \",entity_types.count(label))\n",
        "print('None',\"   :  \",entity_types.count('None'))\n",
        "\n",
        "\n",
        "# create array for each entity \n",
        "entity_type_embeddings_train = np.zeros((len(entity_types), 5))\n",
        "\n",
        "# dictionary to map each entity to its tensor\n",
        "entity_type_dict = {'PERSON': [1, 0, 0, 0, 0], 'CARDINAL': [0, 1, 0, 0, 0], 'DATE': [0, 0, 1, 0, 0], 'ORG': [0, 0, 0, 1, 0], 'GPE': [0, 0, 0, 0, 1], 'None': [0, 0, 0, 0, 0]}\n",
        "\n",
        "\n",
        "for i, entity_type in enumerate(entity_types):\n",
        "    try:\n",
        "      entity_type_embeddings_train[i] = np.array(entity_type_dict[entity_type])\n",
        "    except:  \n",
        "      entity_type_embeddings_train[i] = np.array(entity_type_dict['None'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain entity type of answer using spaCy and create learnable embedding\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "entity_types = []\n",
        "for answer in tqdm(answers_val):\n",
        "    doc = nlp(answer)\n",
        "    if doc.ents:\n",
        "        entity_types.append(doc.ents[0].label_)\n",
        "    else:\n",
        "        entity_types.append('None')\n",
        "\n",
        "\n",
        "# printing frequancy of each label in dataset\n",
        "print('label     :   frequance')\n",
        "for label in nlp.get_pipe(\"ner\").labels:\n",
        "  print(label,\"  :  \",entity_types.count(label))\n",
        "print('None',\"   :  \",entity_types.count('None'))\n",
        "\n",
        "\n",
        "# create array for each entity \n",
        "entity_type_embeddings_val = np.zeros((len(entity_types), 5))\n",
        "\n",
        "# dictionary to map each entity to its tensor\n",
        "entity_type_dict = {'PERSON': [1, 0, 0, 0, 0], 'CARDINAL': [0, 1, 0, 0, 0], 'DATE': [0, 0, 1, 0, 0], 'ORG': [0, 0, 0, 1, 0], 'GPE': [0, 0, 0, 0, 1], 'None': [0, 0, 0, 0, 0]}\n",
        "\n",
        "\n",
        "for i, entity_type in enumerate(entity_types):\n",
        "    try:\n",
        "      entity_type_embeddings_val[i] = np.array(entity_type_dict[entity_type])\n",
        "    except:  \n",
        "      entity_type_embeddings_val[i] = np.array(entity_type_dict['None'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZivEQeIlfunP",
        "outputId": "8fa97c35-5bea-400f-c4dc-5e5c2ba0097f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20302/20302 [02:10<00:00, 156.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label     :   frequance\n",
            "CARDINAL   :   1707\n",
            "DATE   :   1866\n",
            "EVENT   :   59\n",
            "FAC   :   71\n",
            "GPE   :   1213\n",
            "LANGUAGE   :   37\n",
            "LAW   :   26\n",
            "LOC   :   268\n",
            "MONEY   :   143\n",
            "NORP   :   693\n",
            "ORDINAL   :   132\n",
            "ORG   :   2202\n",
            "PERCENT   :   223\n",
            "PERSON   :   1473\n",
            "PRODUCT   :   77\n",
            "QUANTITY   :   158\n",
            "TIME   :   24\n",
            "WORK_OF_ART   :   41\n",
            "None    :   9889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FeedForward Network"
      ],
      "metadata": {
        "id": "Tt6upbaaTDwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NtQHEzKPiuqe"
      },
      "outputs": [],
      "source": [
        "class FFN(torch.nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(hidden_size, num_classes).to(device)\n",
        "        self.softmax = torch.nn.Softmax(dim=-1).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Question Word "
      ],
      "metadata": {
        "id": "3cD0KQrDTrMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3YaLc2hdkiz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d387ab38-baf2-48bf-fe9e-937f81fcaa06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 86821/86821 [00:39<00:00, 2188.71it/s]\n"
          ]
        }
      ],
      "source": [
        "# dictionary to map each token\n",
        "interrogative_words = {'who':0, 'what':1, 'when':2, 'where':3, 'why':4, 'how':5,'which':6,'other':7}\n",
        "\n",
        "found_interrogative_words_train = []\n",
        "for q in tqdm(questions_train):\n",
        "  words = tokenizer.tokenize(q)\n",
        "  for word in words:\n",
        "    found=False\n",
        "    if word.lower() in interrogative_words:\n",
        "        found=True\n",
        "        found_interrogative_words_train.append(interrogative_words[word.lower()])\n",
        "        break\n",
        "  if found==False:\n",
        "        found_interrogative_words_train.append(interrogative_words['other'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary to map each token\n",
        "interrogative_words = {'who':0, 'what':1, 'when':2, 'where':3, 'why':4, 'how':5,'which':6,'other':7}\n",
        "\n",
        "found_interrogative_words_val = []\n",
        "for q in tqdm(questions_val):\n",
        "  words = tokenizer.tokenize(q)\n",
        "  for word in words:\n",
        "    found=False\n",
        "    if word.lower() in interrogative_words:\n",
        "        found=True\n",
        "        found_interrogative_words_val.append(interrogative_words[word.lower()])\n",
        "        break\n",
        "  if found==False:\n",
        "        found_interrogative_words_val.append(interrogative_words['other'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vIuZ_3GgEfq",
        "outputId": "3504fc2b-7dc8-4f8b-9f6c-8afd1ffe8d44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20302/20302 [00:10<00:00, 2020.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to tensors \n",
        "\n",
        "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "entity_type_embeddings_train = torch.from_numpy(entity_type_embeddings_train)\n",
        "interrogative_words_labels_train=torch.tensor(found_interrogative_words_train,dtype=torch.int64)\n",
        "\n",
        "# print(input_ids.shape)\n",
        "# print(len(entity_type_embeddings))\n",
        "# print(len(interrogative_words_labels))\n",
        "\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "entity_type_embeddings_val = torch.from_numpy(entity_type_embeddings_val)\n",
        "interrogative_words_labels_val=torch.tensor(found_interrogative_words_val,dtype=torch.int64)"
      ],
      "metadata": {
        "id": "6i-cz_krZunE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data to TensorDataset "
      ],
      "metadata": {
        "id": "Oea2WAYFVsoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = torch.utils.data.TensorDataset(input_ids_train, attention_masks_train, entity_type_embeddings_train,interrogative_words_labels_train)\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=4,shuffle=True, num_workers=8, pin_memory=True,sampler=None)\n",
        "\n",
        "dataset_val = torch.utils.data.TensorDataset(input_ids_val, attention_masks_val, entity_type_embeddings_val,interrogative_words_labels_val)\n",
        "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=4,shuffle=True, num_workers=8, pin_memory=True,sampler=None)"
      ],
      "metadata": {
        "id": "Gtha0xIJZxCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85a1d8d-4258-442f-82f5-ed47974524b0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model"
      ],
      "metadata": {
        "id": "1w89omWfV75X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GlXisZt-yeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a387c76-72e7-4df9-ed16-2a426ccccb3b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############Train############\n",
            "Batch 1000 / 21706 \n",
            "Loss: 7.5 \n",
            "\n",
            "Batch 2000 / 21706 \n",
            "Loss: 18.6 \n",
            "\n",
            "Batch 3000 / 21706 \n",
            "Loss: 14.2 \n",
            "\n",
            "Batch 4000 / 21706 \n",
            "Loss: 10.8 \n",
            "\n",
            "Batch 5000 / 21706 \n",
            "Loss: 5.6 \n",
            "\n",
            "Batch 6000 / 21706 \n",
            "Loss: 16.8 \n",
            "\n",
            "Batch 7000 / 21706 \n",
            "Loss: 21.3 \n",
            "\n",
            "Batch 8000 / 21706 \n",
            "Loss: 3.3 \n",
            "\n",
            "Batch 9000 / 21706 \n",
            "Loss: 14.1 \n",
            "\n",
            "Batch 10000 / 21706 \n",
            "Loss: 26.9 \n",
            "\n",
            "Batch 11000 / 21706 \n",
            "Loss: 3.3 \n",
            "\n",
            "Batch 12000 / 21706 \n",
            "Loss: 9.7 \n",
            "\n",
            "Batch 13000 / 21706 \n",
            "Loss: 39.5 \n",
            "\n",
            "Batch 14000 / 21706 \n",
            "Loss: 9.0 \n",
            "\n",
            "Batch 15000 / 21706 \n",
            "Loss: 9.0 \n",
            "\n",
            "Batch 16000 / 21706 \n",
            "Loss: 9.7 \n",
            "\n",
            "Batch 17000 / 21706 \n",
            "Loss: 17.9 \n",
            "\n",
            "Batch 18000 / 21706 \n",
            "Loss: 15.7 \n",
            "\n",
            "Batch 19000 / 21706 \n",
            "Loss: 14.2 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the model on the SQuAD v2 dataset\n",
        "ffn = FFN(hidden_size=773, num_classes=8)\n",
        "optimizer = torch.optim.Adam(ffn.parameters(), lr=5e-5, weight_decay=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "epochs = 3\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print_every = 1000\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    epoch_time = time.time()\n",
        "\n",
        "    # Set model in train mode\n",
        "    model.train()\n",
        "    \n",
        "    loss_of_epoch = 0\n",
        "    print(\"\\n############Train############\")\n",
        "\n",
        "    for batch_idx,batch in enumerate(dataloader_train):\n",
        "      \n",
        "        optimizer.zero_grad()\n",
        "        input_ids_batch, attention_masks_batch, entity_type_embeddings_batch,labels= tuple(t.to(device) for t in batch)  #change t.to(device)\n",
        "        outputs = model(input_ids_batch, attention_mask=attention_masks_batch, labels=labels,output_hidden_states=True)\n",
        "\n",
        "        cls_tensor = outputs.hidden_states[-1]\n",
        "        # https://discuss.huggingface.co/t/how-to-get-cls-embeddings-from-bertfortokenclassification-model/9276/2#:~:text=The%20shape%20of%20last_hidden_states%20will%20be%20%5Bbatch_size%2C%20tokens%2C%20hidden_dim%5D%20so%20if%20you%20want%20to%20get%20the%20embedding%20of%20the%20first%20element%20in%20the%20batch%20and%20the%20%5BCLS%5D%20token%20you%20can%20get%20it%20with%20last_hidden_states%5B0%2C0%2C%3A%5D.\n",
        "        cls_tensor = cls_tensor[:,0,:]\n",
        "        cls_tensor = cls_tensor\n",
        "        ner_tensor = entity_type_embeddings_batch.to(torch.float32)\n",
        "\n",
        "        # Concatenate the tensors along the first dimension\n",
        "        concat_tensor = torch.cat((cls_tensor, ner_tensor),dim=1).to(device)\n",
        "\n",
        "        logits = ffn(concat_tensor)\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "        \n",
        "        loss = loss_fn(predictions.float(), labels.float())\n",
        "        loss.requires_grad = True\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_of_epoch += loss.item()\n",
        "\n",
        "        if (batch_idx+1) % print_every == 0:\n",
        "          print(\"Batch {:} / {:}\".format(batch_idx+1,len(dataloader_train)),\"\\nLoss:\", round(loss.item(),1),\"\\n\")\n",
        "\n",
        "        del batch, concat_tensor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    loss_of_epoch /= len(dataloader_train)\n",
        "    train_losses.append(loss_of_epoch)  \n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    print(\"\\n############Evaluate############\")\n",
        "\n",
        "    loss_of_epoch = 0\n",
        "\n",
        "    for batch_idx,batch in enumerate(dataloader_val):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids_batch, attention_masks_batch, entity_type_embeddings_batch,labels= tuple(t.to(device) for t in batch)  #change t.to(device)\n",
        "        outputs = model(input_ids_batch, attention_mask=attention_masks_batch, labels=labels,output_hidden_states=True)\n",
        "\n",
        "        cls_tensor = outputs.hidden_states[-1]\n",
        "        # https://discuss.huggingface.co/t/how-to-get-cls-embeddings-from-bertfortokenclassification-model/9276/2#:~:text=The%20shape%20of%20last_hidden_states%20will%20be%20%5Bbatch_size%2C%20tokens%2C%20hidden_dim%5D%20so%20if%20you%20want%20to%20get%20the%20embedding%20of%20the%20first%20element%20in%20the%20batch%20and%20the%20%5BCLS%5D%20token%20you%20can%20get%20it%20with%20last_hidden_states%5B0%2C0%2C%3A%5D.\n",
        "        cls_tensor = cls_tensor[:,0,:]\n",
        "        cls_tensor = cls_tensor\n",
        "        ner_tensor = entity_type_embeddings_batch.to(torch.float32)\n",
        "\n",
        "        # Concatenate the tensors along the first dimension\n",
        "        concat_tensor = torch.cat((cls_tensor, ner_tensor),dim=1).to(device)\n",
        "\n",
        "        logits = ffn(concat_tensor)\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "        \n",
        "        loss = loss_fn(predictions.float(), labels.float())\n",
        "        loss.requires_grad = True\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_of_epoch += loss.item()\n",
        "\n",
        "        if (batch_idx+1) % print_every == 0:\n",
        "          print(\"Batch {:} / {:}\".format(batch_idx+1,len(dataloader_val)),\"\\nLoss:\", round(loss.item(),1),\"\\n\")\n",
        "\n",
        "        del batch, concat_tensor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    loss_of_epoch /= len(dataloader_val)\n",
        "    val_losses.append(loss_of_epoch)  \n",
        "\n",
        "\n",
        "    print(\"\\n-------Epoch \", epoch+1,\n",
        "      \"-------\"\n",
        "      \"\\n Training Loss:\", train_losses[-1],\n",
        "      \"\\n validation Loss:\", train_losses[-1],\n",
        "      \"\\n Time: \",(time.time() - epoch_time),\n",
        "      '\\n predictions :',predictions,\n",
        "      '\\n actual :',labels,\n",
        "      \"\\n-----------------------\",\"\\n\\n\")\n",
        "\n",
        "# Evaluate the model on the SQuAD v2 dataset\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     input_ids = []\n",
        "#     attention_masks = []\n",
        "#     entity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "fig,ax = plt.subplots(1,1,figsize=(15,10))\n",
        "\n",
        "ax.set_title(\"Train Losses\",size=20)\n",
        "ax.set_ylabel('Loss', fontsize = 20) \n",
        "ax.set_xlabel('Epochs', fontsize = 25) \n",
        "\n",
        "_=ax.plot(train_losses)\n",
        "# _=ax.plot(val_losses)\n",
        "# _=ax.legend(('Train','Val'),loc='upper right')\n",
        "_=ax.legend(('Train'),loc='upper right')"
      ],
      "metadata": {
        "id": "89nuuR8pNv1D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "d1ad944e-bf34-431f-ec70-020078026d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAJwCAYAAADWVLPQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABnHElEQVR4nO3dd3hU17318fVTByEJgYSQ6L1LIHAFV1ywQbbjbkNuumPcS9zixHGKY8dO3DGOb+Kbmxfcu8C9G3cQSPTeJXov6vv9Y4ZchQAWQtKe8v08j57RnHNmZul4PGLpnLO3OecEAAAAAIhcMb4DAAAAAACaFsUPAAAAACIcxQ8AAAAAIhzFDwAAAAAiHMUPAAAAACIcxQ8AAAAAIhzFDwAQkczMmdnHvnMAABAKKH4AgCYRLF6H8/VD35kPh5mdTLkEAISLON8BAAAR67cHWHaDpDRJj0jatt+6WY38+v0k7Wnk5wQAICyZc853BgBAlDCzFZK6SOrmnFvhN82RMbOTJX0k6RPn3MlewwAA8B041RMA4J2ZfRw8bTLBzO4ys4VmVmFm/wiuTzOzW8zsQzNbY2aVZrbRzN4ws+MO8pz/cRqmmd0dXH6ymV1oZt+Y2R4z22Jmz5lZhyb8GbPNbIKZraiT/xUzG3qAbRPM7DozKzKzrcGMK8zsdTM7bb9tTzCzwuB+qTCzdWb2lZn95gDP29LM7jCzWWa228x2mdmXZnbZAbY1M/uBmX0RzFpuZqvN7B0zu6Rx9w4AoKlxqicAIJS8LOkoSW9Jek3ShuDyfpLukfSppKmStkrqLOkcSWeZWYFz7u3DeJ2rgo99Q9Inko6RdImkPDMb7JyrOPIf5f+YWTdJ0yTlSPpQ0rOSOkm6SNJoM7vAOTelzkP+IekySXMk/VPS3uBjR0gaJen94POOUmB/7Aj+LGsltVFgf12lOqfbmlnr4GsPkVQk6WkF/gB8pqRnzGyAc+5XdTLcI+kOScslvSBpu6RsBf77XCTp+SPdLwCA5kPxAwCEki6SBjrnNu23fL6knP2Xm1lHSd9IekjS4RS/UZKOcs7NrvNczyhQts5VoOg0picVKG6/cs7dU+c1n1CgzP6vmXVxzu0yszRJl0qaIekY51xN3Scys7Z17v5MgfJ2snOueL/tMvbL8LACpe8259z9dbZLUqBk/9LMXnLOzQqu+rkCRXKgc+7frpU8wHMDAEIcp3oCAELJrw9Q+uSc236Q5WskvSSpr5l1PozXebRu6Qv67+Dt0YfxPN8pWE7PkLRK0v111znnvlDg6F8bSefvWyzJJFVIqt3/+Zxzmw/wMnsPsN2/9lewLI6TNL1u6QtuVy7ptuBrXr7f01RJqtlvmQ703wIAENo44gcACCXfHGyFmQ2XdL2k4yS1k5Sw3yYdFChX9TH9AMtWB2/T6/kc9TUkePuZc67qAOs/VKCUDZH0T+fcDjMrlFQgaZaZvSzpM0lf73/kTdJkBQrj12b2vAKDzXweLMR1HSUpVpIzs7sPkCE+eNtvv+e+VtI8M3tBgVNiv3TObf/OnxgAEHIofgCAULLuQAvN7HsKHNkrl/SepKWSditwROxkSSdJSjyM19l2gGXVwdvYw3ie+kgL3pYdZP2+5a3rLLtEgaNwl+v/rtMrN7OXJP3CObdekpxzr5jZGEk3S/qxAqdnysxmSLrDOfde8LH7Tg89Kvh1MK3qfH+jpGWSfiTp9uBXtZm9Kelm59ySQzwPACDEUPwAACHDHXyOod9LqpQ0zDk3v+4KM/urAsUvVO07Qtb+IOuz99tOzrm9ku6WdLeZdZJ0oqQfKnBksKukE+psO1XSVDNLVmCQmjGSxkuaYmZDnHPz6jz3Q865m+oTOnht4cOSHjazdgoMLHOpAgO7DAgOBtOog+AAAJoO1/gBAMJBT0nzDlD6YhQoJKFsZvB2hJkd6A+upwRviw70YOfcaufcZAVG31wSfJ62B9hut3Puw2Cx+6MCp8KeFVz9jQJHR0/Y/3H14Zzb4Jx7xTl3sQKnpvaQNLAhzwUA8IPiBwAIBysk9TKznH0LzMwUOCrW31Omegleb/eeAkfqbqi7zsyOUeB0zq2SXg0uyzSzQQd4qmQFTsWsVuDop8zsxIOUyazg7Z5ghg0KXLM3zMx+bWb/cTqrmfUITjshM0sMXlO5/zbxCgxE86/nBgCEB071BACEg4cUmBJhZnCwkypJwxUoffsGQvGl776J5g9glXPuLklXSvpc0gNmdoYCg8vsm8evVtKPnHM7g4/poMDPOVtSiQKDzqQqcApnewVGJN237aOSOpjZ5wqU40pJQyWdKmmlpOfqZLlGUi9Jv5P0fTObJmm9AtNM9FPg2r/LFJi3r4WkaWa2RIFpJVZKSpJ0enDbN/Y/+goACG0UPwBAyHPO/dXMKhQ4YvYDBaYv+EyBgUcukN/ilxXMdCDFku5yzi0zs2GSfiXpbAUGpNmhwNyD9zjnvq3zmBWSfhPc5hRJGZK2SFqowAArdcvcHyV9T9IwSacpUCJXBZc/7Jzbum/D4GihJ0m6QoGjjBcoUObWS1qswGAu+waD2a3A4DKnSDpe0nmSdiowqM54BSZ/BwCEETv4dfQAAAAAgEjANX4AAAAAEOEofgAAAAAQ4Sh+AAAAABDhKH4AAAAAEOEofgAAAAAQ4SJmOoeMjAzXtWtX3zEAAAAAwIsZM2Zscs5lHmhdxBS/rl27avr06b5jAAAAAIAXZrbyYOs41RMAAAAAIhzFDwAAAAAiHMUPAAAAACJcxFzjBwAAAABHqqqqSmvWrFF5ebnvKAeVlJSkjh07Kj4+vt6PofgBAAAAQNCaNWuUkpKirl27ysx8x/kPzjlt3rxZa9asUbdu3er9OE71BAAAAICg8vJytW3bNiRLnySZmdq2bXvYRyQpfgAAAABQR6iWvn0ako9TPQEAAAAgRGzevFkjR46UJK1bt06xsbHKzAzMyf7NN98oISGhQc9L8QMAAACAENG2bVvNmjVLknT33XerVatW+sUvfnHEz+v1VE8z62RmH5nZPDOba2bXB5e3MbP3zGxx8DbdZ04AAAAACGe+r/GrlnSzc66/pGMlXW1m/SXdLukD51wvSR8E7wMAAAAAGsDrqZ7OuTJJZcHvd5rZfEkdJJ0r6eTgZv8r6WNJt3mICAAAACBK/bZwruaV7mjU5+yfk6rfFAxo1OesD99H/P7FzLpKGiLpa0lZwVIoSeskZfnKBQAAAADhLiQGdzGzVpJelnSDc25H3eFJnXPOzNxBHneFpCskqXPnzs0RFQAAAECU8HFkrql4P+JnZvEKlL7JzrlXgovXm1l2cH22pA0Heqxz7inn3DDn3LB9Q5wCAAAAAP6d1yN+Fji093dJ851zD9ZZ9YakH0i6L3j7uod4AAAAAODN3Xff3WjP5ftUz+GSvi9ptpnNCi77pQKF7wUz+4mklZIu9hMPAAAAAMKf71E9p0myg6we2ZxZAAAAACBSeb/GDwAAAADQtCh+AAAAAFCHcwecVCBkNCQfxQ8AAAAAgpKSkrR58+aQLX/OOW3evFlJSUmH9Tjfg7tENOecqmqcEuLo1wAAAEA46Nixo9asWaONGzf6jnJQSUlJ6tix42E9huLXRJxzuv65WYqLNf3lojzVnZQeAAAAQGiKj49Xt27dfMdodByKaiJmpm4ZyXqlaK2e/Wa17zgAAAAAohjFrwldN7KXTuiVobvfmKvZa7b7jgMAAAAgSlH8mlBsjOmRS4coo1WCxk+eoW17Kn1HAgAAABCFKH5NrE1ygiaMzdf6HeW66YVi1daG5uhAAAAAACIXxa8ZDOmcrl+P6a8PF2zQxE+W+o4DAAAAIMpQ/JrJ94/tonPycvSXdxfq8yWbfMcBAAAAEEUofs3EzHTv+YPUPbOVrnt2ptZtL/cdCQAAAECUoPg1o+TEOD05Ll97q2p09TNFqqqp9R0JAAAAQBSg+DWznu1S9KcLcjVj5Vbd++YC33EAAAAARAGKnwcFeTn64fFd9fTnyzW1pMx3HAAAAAARjuLnyS/P7qchnVvr1peKtXTjLt9xAAAAAEQwip8nCXExmnB5vhLjYzV+0gztqaz2HQkAAABAhKL4eZTTuoUeuXSwFm/YpTtfnSPnmNwdAAAAQOOj+Hl2Qq9M3TCyt16duVaTv17lOw4AAACACETxCwHXntpTJ/XO1O8K56lkzTbfcQAAAABEGIpfCIiJMT18yWBlpiRq/KQibd1d6TsSAAAAgAhC8QsR6ckJemJsvjburNCNL8xSbS3X+wEAAABoHBS/EJLXqbV+XdBfHy/cqMc/WuI7DgAAAIAIQfELMeOO6azzBufoofcX6bPFG33HAQAAABABKH4hxsz0x/MHqVe7Vrr+uVkq3bbXdyQAAAAAYY7iF4JaJsRp4rihqqiq0dXPFKmyutZ3JAAAAABhjOIXonpkttL9F+Zp5qpt+uOb833HAQAAABDGKH4hbHRutn40vKv+8cUKFRaX+o4DAAAAIExR/ELcHWf1U37n1rr95RIt2bDLdxwAAAAAYYjiF+IS4mI0YWy+EuNjNX7SDO2uqPYdCQAAAECYofiFgey0Fnr00iFasnGXfvnqbDnH5O4AAAAA6o/iFyZG9MrQTaf11uuzSjXpq5W+4wAAAAAIIxS/MHL1KT11Sp9M/W7KPM1avc13HAAAAABhguIXRmJiTA9dMlhZqUm6enKRtuyu9B0JAAAAQBig+IWZ1i0T9MTYfG3cWaEbnp+lmlqu9wMAAABwaBS/MJTbsbV+c05/fbpoox77cLHvOAAAAABCHMUvTF1+dGedP6SDHvlgsT5ZtNF3HAAAAAAhjOIXpsxM93xvkHq3S9ENz83U2m17fUcCAAAAEKIofmGsRUKsJo7LV1WN09WTi1RZXes7EgAAAIAQRPELc90zW+n+C3M1a/U23TN1nu84AAAAAEIQxS8CnD0oWz8Z0U3/++VKvVFc6jsOAAAAgBBD8YsQt5/VV8O6pOv2l0u0eP1O33EAAAAAhBCKX4SIj43R45fnq2VCrMZPLtLuimrfkQAAAACECIpfBGmflqRHLx2iZRt36fZXZss5JncHAAAAQPGLOMf3zNDNZ/RRYXGp/vnlSt9xAAAAAIQAil8EGn9SD43s205/mDpPRau2+o4DAAAAwDOKXwSKiTE9ePFgtU9L0tWTi7R5V4XvSAAAAAA8ovhFqLSW8Zo4dqg2767UDc/PUk0t1/sBAAAA0YriF8EGdkjTb88ZoM8Wb9IjHyz2HQcAAACAJxS/CHfpUZ10QX5HPfbhYn28cIPvOAAAAAA8oPhFODPTH84bqD5ZKbrh+Vlas3WP70gAAAAAmhnFLwq0SIjVxHFDVVPjdPXkIlVU1/iOBAAAAKAZUfyiRLeMZD1wUa6K12zXH6bM9x0HAAAAQDOi+EWRUQOz9bMTuun/fbVSr89a6zsOAAAAgGZC8Ysyt47qq6O6puv2l2dr0fqdvuMAAAAAaAYUvygTHxujxy/PV3JinK6cNEO7Kqp9RwIAAADQxCh+USgrNUmPXTZEKzbt1m0vl8g5JncHAAAAIhnFL0od16Otbjmzr6aWlOkfX6zwHQcAAABAE6L4RbErT+qu0/pl6Z6p8zVj5RbfcQAAAAA0EYpfFDMz/eXiPOW0bqGrJ8/Upl0VviMBAAAAaAIUvyiX1iJeT4zN15Y9lbr+uZmqqeV6PwAAACDSUPyggR3S9PtzB+jzJZv18PuLfMcBAAAA0MgofpAkXXJUZ100tKMe+3CJPlqwwXccAAAAAI2I4od/+f15A9UvO1U3PD9Lq7fs8R0HAAAAQCOh+OFfkuJjNXFsvmprna5+pkgV1TW+IwEAAABoBBQ//JuuGcn688V5KlmzXb8rnOc7DgAAAIBGQPHDfzhzQHv9/MTumvz1Kr06c43vOAAAAACOEMUPB3TLmX10dLc2uuOV2Vq4bqfvOAAAAACOAMUPBxQXG6PHLx+ilKR4jZ80QzvLq3xHAgAAANBAFD8cVLuUJD1+2RCt3LJHt71cIueY3B0AAAAIRxQ/HNIx3dvq1jP76M3Z6/T3act9xwEAAADQABQ/fKcrTuyuM/pn6b63Fmj6ii2+4wAAAAA4TBQ/fCcz0wMX5alDegtd/UyRNu2q8B0JAAAAwGGg+KFe0lrEa+LYodq2p0rXPTtTNbVc7wcAAACEC4of6q1/Tqp+f95AfbF0sx58b6HvOAAAAADqieKHw3LxsE66ZFgnTfhoqT6Yv953HAAAAAD1QPHDYfvtuQPUPztVNz4/S6u37PEdBwAAAMB3oPjhsCXFx+rJcUPlJI2fPEPlVTW+IwEAAAA4BIofGqRz25Z68OLBmrN2h35bOM93HAAAAACHQPFDg53eP0vjT+6hZ79ZpZdnrPEdBwAAAMBBUPxwRG4+vbeO695Wd742WwvW7fAdBwAAAMABUPxwROJiY/ToZUOUmhSv8ZOKtKO8ynckAAAAAPuh+OGIZaYk6vHL87Vqyx7d+mKJnGNydwAAACCUUPzQKI7u1ka3j+qrt+eu098+W+47DgAAAIA6KH5oND89oZtGDWiv+95eoG+Wb/EdBwAAAEAQxQ+Nxsx0/0W56pTeQtc8U6QNO8t9RwIAAAAgih8aWWpSvCaOG6od5VW67tmZqq6p9R0JAAAAiHoUPzS6ftmp+sN5g/TVsi36y3uLfMcBAAAAoh7FD03iwqEdddnRnTTx46V6b95633EAAACAqOa1+JnZ02a2wczm1Fk22My+MrNZZjbdzI72mREN95uCARrYIVU3vTBLqzbv8R0HAAAAiFq+j/j9Q9Ko/ZbdL+m3zrnBku4K3kcYSoqP1cSxQ2WSxk+eofKqGt+RAAAAgKjktfg55z6VtP+4/05SavD7NEmlzRoKjapTm5Z6+NLBmlu6Q3e/Mdd3HAAAACAq+T7idyA3SHrAzFZL+rOkO/zGwZE6tW+Wrj6lh577drVenL7adxwAAAAg6oRi8Rsv6UbnXCdJN0r6+8E2NLMrgtcBTt+4cWOzBcThu+n0Pjq+R1v96rU5mle6w3ccAAAAIKqEYvH7gaRXgt+/KOmgg7s4555yzg1zzg3LzMxslnBomNgY06OXDVHrlvEaP3mGtu+t8h0JAAAAiBqhWPxKJZ0U/P5USYs9ZkEjymiVqAmX52vt1r265cViOed8RwIAAACigu/pHJ6V9KWkPma2xsx+Iulnkv5iZsWS/ijpCp8Z0biGdW2j28/qq3fnrddTny7zHQcAAACICnE+X9w5d9lBVg1t1iBoVj8Z0U1Fq7bq/ncWanCn1jqme1vfkQAAAICIFoqneiLCmZn+dEGuurRpqWuenakNO8p9RwIAAAAiGsUPXqQkxeuJcfnaWV6la56dqeqaWt+RAAAAgIhF8YM3fdun6o/fG6Rvlm/RA+8u9B0HAAAAiFgUP3h1fn5HjT2ms/76yTK9O3ed7zgAAABARKL4wbu7Cvort2Oabn6xWCs37/YdBwAAAIg4FD94lxgXqwmX5yvGTFdOKlJ5VY3vSAAAAEBEofghJHRq01IPXzJY88t26K7X5/iOAwAAAEQUih9Cxil92+naU3vqhelr9Py3q3zHAQAAACIGxQ8h5YbTemtEzwz9+vW5mrN2u+84AAAAQESg+CGkxMaYHrl0sNq0TNBVk4u0fW+V70gAAABA2KP4IeS0bZWoCWPzVbptr25+oVi1tc53JAAAACCsUfwQkoZ2Sdcvz+6n9+ev118/XeY7DgAAABDWKH4IWT8a3lWjc7P1wDsL9OXSzb7jAAAAAGGL4oeQZWb60wW56pqRrGufnakNO8p9RwIAAADCEsUPIa1VYpyeHDdUuyuqdc0zM1VVU+s7EgAAABB2KH4Ieb2zUnTv+YP0zYoteuCdhb7jAAAAAGGH4oewcN6QDvr+sV301KfL9Pacdb7jAAAAAGGF4oew8asx/ZTXqbVuebFYyzft9h0HAAAACBsUP4SNxLhYTbh8iGJjTeMnzdDeyhrfkQAAAICwQPFDWOmY3lIPXzJYC9fv1K9emyPnmNwdAAAA+C4UP4Sdk/u007Wn9tLLRWv03LerfccBAAAAQh7FD2Hp+pG9dEKvDP3mjbmas3a77zgAAABASKP4ISzFxpgeuXSI2iYn6MpJM7R9T5XvSAAAAEDIovghbLVJTtCEsflav6NcN70wS7W1XO8HAAAAHAjFD2Etv3O67jy7nz5YsEETP1nqOw4AAAAQkih+CHs/OL6rCvJy9Jd3F+qLpZt8xwEAAABCDsUPYc/MdN/5g9QtI1nXPTtT67aX+44EAAAAhBSKHyJCcmKcnhw3VHsqa3TNM0Wqqqn1HQkAAAAIGRQ/RIxeWSm674JcTV+5VX96a4HvOAAAAEDIoPghopyTl6MfHNdFf5u2XG/NLvMdBwAAAAgJFD9EnDtH99fgTq11y0slWrZxl+84AAAAgHcUP0SchLgYTRibr/hY0/hJRdpTWe07EgAAAOAVxQ8RqUPrFnrk0iFatGGnfvXqHDnH5O4AAACIXhQ/RKwTe2fq+pG99MrMtXrmm1W+4wAAAADeUPwQ0a47tZdO7J2p374xTyVrtvmOAwAAAHhB8UNEi4kxPXzJYGW0StD4SUXatqfSdyQAAACg2VH8EPHaJCfoiXFDtWFnuW58fpZqa7neDwAAANGF4oeoMLhTa/16TH99tHCjnvh4ie84AAAAQLOi+CFqfP/YLjp3cI4efG+RPl+yyXccAAAAoNlQ/BA1zEz3nj9IPTJb6bpnZ2rd9nLfkQAAAIBmQfFDVGmZEKeJ44aqvKpGVz9TpKqaWt+RAAAAgCZH8UPU6dmulf50Ya5mrNyqe99c4DsOAAAA0OQofohKY3Jz9MPju+rpz5drakmZ7zgAAABAk6L4IWr98ux+yu/cWre+VKwlG3b5jgMAAAA0GYofolZCXIwmjM1XYnysrpo8Q3sqq31HAgAAAJoExQ9RLTuthR65dLAWb9ilX74yW84xuTsAAAAiD8UPUe+EXpm68bTeem1WqSZ9vcp3HAAAAKDRUfwASdec0lMn98nU7wvnqXj1Nt9xAAAAgEZF8QMkxcSYHrp4sDJTEnXV5CJt3V3pOxIAAADQaCh+QFB6coKeGJuvjTsrdOMLs1Rby/V+AAAAiAwUP6COvE6tdVdBf328cKMe/2iJ7zgAAABAo6D4AfsZe0xnfW9IBz30/iJ9tnij7zgAAADAEaP4AfsxM93zvYHq1a6Vrn9ulkq37fUdCQAAADgiFD/gAFomxGniuKGqrK7V1c8UqbK61nckAAAAoMEofsBB9MhspfsvzNXMVdv0xzfn+44DAAAANBjFDziEswdl68fDu+kfX6zQG8WlvuMAAAAADULxA77DHWf31dAu6br95RIt2bDTdxwAAADgsFH8gO8QHxujCZfnq0V8rK6cVKTdFdW+IwEAAACHheIH1EP7tCQ9etkQLdu4S3e8MlvOMbk7AAAAwgfFD6in4T0zdNPpvfVGcan+31crfccBAAAA6o3iBxyGq07uqVP7ttPvp8zTzFVbfccBAAAA6oXiBxyGmBjTgxfnKSs1SVdPLtKW3ZW+IwEAAADfieIHHKbWLRM0cexQbdpVqRuen6WaWq73AwAAQGij+AENMKhjmu4+Z4A+XbRRj3242HccAAAA4JAofkADXXZ0J52f30GPfLBYnyza6DsOAAAAcFAUP6CBzEz3nDdIfbJSdMNzM7V2217fkQAAAIADovgBR6BFQqyeGJuvqhqnqyYXqaK6xnckAAAA4D9Q/IAj1D2zlf58Ua6KV2/TPVPn+44DAAAA/AeKH9AIRg3M1k9HdNM/v1yp12et9R0HAAAA+DcUP6CR3HZWXx3VNV23vzxbi9fv9B0HAAAA+BeKH9BI4mNj9Pjl+UpOjNWVk2ZoV0W170gAAACAJIof0KiyUpP06GVDtHzTbt3+comcY3J3AAAA+EfxAxrZ8T0ydPMZfTSlpEz/+8UK33EAAAAAih/QFMaf1EOn9Wune96cr6JVW33HAQAAQJSj+AFNICbG9JeLBqt9WpKunlykzbsqfEcCAABAFKP4AU0krWW8Jo4dqs27K3XD87NUU8v1fgAAAPCD4gc0oYEd0vS7cwbos8Wb9MgHi33HAQAAQJSi+AFN7JKjOunCoR312IeL9dHCDb7jAAAAIApR/IAmZmb6/bkD1ScrRTc+P0trtu7xHQkAAABRhuIHNIMWCbF6ctxQ1dQ4XTW5SBXVNb4jAQAAIIpQ/IBm0jUjWQ9clKeSNdv1+ynzfMcBAABAFKH4Ac1o1MD2uuLE7pr01Sq9NnOt7zgAAACIEhQ/oJndemYfHd21je54ZbYWrd/pOw4AAACiAMUPaGZxsTF6/PIhSk6M05WTZmhXRbXvSAAAAIhwFD/Ag3apSXrssiFasWm3bnupRM4xuTsAAACaDsUP8OS4Hm1166i+mjq7TP/z+QrfcQAAABDBKH6ARz8/sbtO75+lP745XzNWbvEdBwAAABGK4gd4ZGb680V56pDeQldPnqlNuyp8RwIAAEAEovgBnqW1iNcTY/O1dU+lrn9upmpqud4PAAAAjctr8TOzp81sg5nN2W/5tWa2wMzmmtn9vvIBzWVATpp+f+5Afb5ksx5+f5HvOAAAAIgwvo/4/UPSqLoLzOwUSedKynPODZD0Zw+5gGZ38VGddPGwjnrswyX6cMF633EAAAAQQbwWP+fcp5L2H9FivKT7nHMVwW02NHswwJPfnTtQ/bNTdePzxVq9ZY/vOAAAAIgQvo/4HUhvSSeY2ddm9omZHeU7ENBckuJjNXFcvmqd01WTi1ReVeM7EgAAACJAKBa/OEltJB0r6RZJL5iZHWhDM7vCzKab2fSNGzc2Z0agyXRpm6y/XJSn2Wu363dT5vmOAwAAgAgQisVvjaRXXMA3kmolZRxoQ+fcU865Yc65YZmZmc0aEmhKZwxor5+f1F3PfL1KrxSt8R0HAAAAYS4Ui99rkk6RJDPrLSlB0iafgQAfbjmjj47p1ka/fHW2Fqzb4TsOAAAAwpjv6RyelfSlpD5mtsbMfiLpaUndg1M8PCfpB845JjZD1ImLjdFjlw9RSlK8xk8q0s7yKt+RAAAAEKZ8j+p5mXMu2zkX75zr6Jz7u3Ou0jk3zjk30DmX75z70GdGwKd2KUmacHm+Vm3Zo1tfKhF/AwEAAEBDhOKpngDqOLpbG902qo/emrNOf5+23HccAAAAhCGKHxAGfnZCd505IEv3vbVA01fsP/UlAAAAcGgUPyAMmJkeuChPHdNb6OpnirRpV4XvSAAAAAgjFD8gTKQmxeuJsUO1bU+Vrn1mpqpran1HAgAAQJig+AFhpH9Oqv5w3kB9uWyzHnxvke84AAAACBMUPyDMXDSsky49qpOe+Hip3p+33nccAAAAhAGKHxCG7j5ngAbkpOqmF2Zp1eY9vuMAAAAgxFH8gDCUFB+riWOHSpKuemaGyqtqPCcCAABAKKP4AWGqc9uWevDiwZqzdod+WzjXdxwAAACEMIofEMZO65+l8Sf30LPfrNZLM9b4jgMAAIAQRfEDwtzNp/fWcd3b6s5XZ2t+2Q7fcQAAABCCKH5AmIuLjdGjlw1RWot4jZ80QzvKq3xHAgAAQIih+AERIDMlURPG5mv11r269cUSOed8RwIAAEAIofgBEeKorm10x1l99fbcdfrbZ8t9xwEAAEAIofgBEeQnI7rprIHtdd/bC/TN8i2+4wAAACBEUPyACGJmuv/CXHVu01LXPFOkDTvLfUcCAABACKD4AREmJSleE8fla0d5la59Zqaqa2p9RwIAAIBnFD8gAvVtn6p7zhukr5dv0Z/fXeQ7DgAAADyj+AER6oKhHXXZ0Z315CdL9d689b7jAAAAwCOKHxDBflPQXwM7pOqmF2Zp5ebdvuMAAADAE4ofEMGS4mM1cexQxZhp/KQilVfV+I4EAAAADyh+QITr1KalHrokT/PKdug3r8/1HQcAAAAeUPyAKHBq3yxdc0pPPT99tV6Yvtp3HAAAADQzih8QJW48vbeG92yrX782R3NLt/uOAwAAgGZE8QOiRGyM6ZFLhyi9ZYKumlyk7XurfEcCAABAM6H4AVEko1WiJowdorVb9+qWF4vlnPMdCQAAAM2A4gdEmaFd2uiOs/vp3Xnr9dSny3zHAQAAQDOg+AFR6MfDu2r0oGzd/85CfbVss+84AAAAaGIUPyAKmZnuu2CQurRpqWuemakNO8p9RwIAAEATovgBUSolKV4Txw3V7opqXfPsTFXX1PqOBAAAgCZC8QOiWJ/2Kfrj+QP1zfIteuCdhb7jAAAAoIlQ/IAo970hHTX2mM7666fL9M7cdb7jAAAAoAlQ/ADoroL+yu2Ypl+8UKwVm3b7jgMAAIBGRvEDoMS4WE24PF+xsabxk4tUXlXjOxIAAAAaEcUPgCSpU5uWeuiSwVqwbod+/doc33EAAADQiCh+AP7llD7tdO0pPfXijDV6/ttVvuMAAACgkVD8APyb60/rrRN6ZejXr8/VnLXbfccBAABAI6D4Afg3sTGmhy8ZrLbJCbpqcpG2763yHQkAAABH6LCLn5mlm1l/M0vcb/mPzOx1M3vGzI5uvIgAmlvbVol6/PJ8lW7bq5tfKFZtrfMdCQAAAEegIUf8/ijp67qPNbNrJf1NUoGkSyV9bGb9GyUhAC+GdknXnaP76f356/XXT5f5jgMAAIAj0JDiN1zSB865vXWW/ULSWkknSro4uOymI8wGwLMfHt9Vo3Oz9cA7C/TF0k2+4wAAAKCBGlL8Okhavu9O8MheJ0mPOeemOedeklSoQAkEEMbMTH+6IFfdMpJ13bMztX5Hue9IAAAAaICGFL8Wkur+62+4JCfp/TrLlipQEAGEuVaJcZo4bqh2V9TommeKVFVT6zsSAAAADlNDit9aSX3r3D9T0g5JxXWWpUuqeyoogDDWOytF910wSN+u2Kr7317gOw4AAAAOU1wDHvORpB+Y2TUKHPk7R9LLzrm6hwF6SFrdCPkAhIhzB3fQ9BVb9d+fLdfQLukaNTDbdyQAAADUU0OO+N0raZekRyQ9pUD5u3vfSjNLlTRC0heNkA9ACPnVmH7K69Rat7xYouWbdvuOAwAAgHo67OLnnFsuaYCk6yVdJ2mgc25hnU16SvqrpH80RkAAoSMxLlZPjM1XXKxp/KQZ2ltZ4zsSAAAA6qEhR/zknFvnnHs8+LVqv3VFzrkbnXPfNk5EAKGkQ+sWevjSIVq4fqd+9docOcfk7gAAAKGuQcXvQMysrZl9z8zONLPYxnpeAKHnpN6Zuu7UXnq5aI2e+5bLeQEAAELdYRc/MxtvZl+bWZs6y4ZKWiDpJUlvSvrCzJIbLyaAUHPdyF46oVeGfvPGXM1Zu913HAAAABxCQ474XSLJOee21Fn2gAJTOPyPAsXvKElXHnk8AKEqNsb0yKVDlJGcoCsnzdC2PZW+IwEAAOAgGlL8ekkq2XfHzDIknSTp7865nzrnCiR9K+nyxokIIFS1SU7QhLH5Wr+jXDe9UKzaWq73AwAACEUNKX5tJW2oc3948PbVOss+k9SloaEAhI8hndP1q9H99eGCDZr4yVLfcQAAAHAADSl+WyRl1Ll/kqRa/fu8fU5S0hHkAhBG/uu4LirIy9Ff3l2oz5ds8h0HAAAA+2lI8ZsvqSA4imdrSZdK+tY5t6PONl0lrTvyeADCgZnpvvMHqXtmK1337Eyt217uOxIAAADqaEjxe0RStqQ1klZLypL0xH7bHCup+MiiAQgnyYlxenJcvvZW1eiaZ4pUVVPrOxIAAACCDrv4OefeUGDEzrmSFkr6hXNu0r71ZnaypFaS3mmciADCRc92KbrvglxNX7lV9721wHccAAAABMU15EHOuackPXWQdR8rMLUDgCh0Tl6OilZu1d+nLdfQLuk6e1C270gAAABRryGnegLAIf3y7H4a0rm1bn2pRMs27vIdBwAAIOo1uPiZ2bFm9jczm2FmS82syMz+28yOb8yAAMJPQlyMJlyer4S4GI2fVKQ9ldW+IwEAAES1BhU/M/uDpM8l/VjSEEndJA2W9BNJn5nZHxsrIIDwlNO6hR65dLAWbdipX706R84xuTsAAIAvh138zOwiSb+UtErSTyV1l9QiePvT4PLbzOziRswJIAyd0CtTN4zsrVdmrtUz36zyHQcAACBqNeSI37WS1ks6yjn3tHNuhXOuInj7tKSjJG2UdHVjBgUQnq49tadO6p2p374xTyVrtvmOAwAAEJUaUvzyJL3knNt0oJXB5S8qcOongCgXE2N6+JLBykxJ1PhJRdq6u9J3JAAAgKjTkOIXJ2nPd2yzRw2cKgJA5ElPTtCEsfnasLNcN74wS7W1XO8HAADQnBpS/JZKGmNmB3xscPnZwe0AQJI0uFNr3TWmvz5euFETPlriOw4AAEBUaUjxe0ZSP0mvm1mvuivMrIeklyT1D24HAP8y7tguOndwjh58f5GmLT7g2eIAAABoAg0pfg9K+lTSaEnzzWyVmX1tZislLZR0ngJTPTzYaCkBRAQz073nD1LPzFa67rmZKtu+13ckAACAqHDYxc85VynpdEl3SlouqaMCI3l2Ct6/U9LI4HYA8G9aJsRp4rihqqiq0dWTi1RZXes7EgAAQMRr0ATuzrkq59y9zrleklIVKH2pzrlezrl7JcWaWWpjBgUQOXq2a6X7L8xT0aptuvet+b7jAAAARLwGFb+6nHO7nHNrnXO76iyeKGnLkT43gMg1OjdbPxreVf/z+QpNKSn1HQcAACCiHXHxOwRrwucGEAHuOKuf8ju31m0vlWjJhl3f/QAAAAA0SFMWPwA4pIS4GE0Ym6/E+FhdNXmG9lRW+44EAAAQkSh+ALzKTmuhRy8dosUbdumXr8yWc0zuDgAA0NgofgC8G9ErQzed1luvzSrVpK9X+Y4DAAAQcSh+AELC1af01Cl9MvW7wrmatXqb7zgAAAARheIHICTExJgeumSw2qUk6erJRdq6m6lAAQAAGku9ip+Z1RzOl6T/auLcACJQ65YJmjguXxt3VuiG52eptpbr/QAAABpDfY/4WQO+AOCw5XZsrbsK+uuTRRv12IdLfMcBAACICHH12cg5xymhAJrN2GM6q2jlVj38wSIN6dxaJ/bO9B0JAAAgrFHoAIQcM9M93xuk3u1SdP1zM1W6ba/vSAAAAGGN4gcgJLVIiNXEcfmqqnG6anKRKqtrfUcCAAAIWxQ/ACGre2Yr3X9hrmat3qY/vjnfdxwAAICwRfEDENLOHpStn4zopn98sUJvFJf6jgMAABCWKH4AQt7tZ/XVsC7puv3lEi3ZsNN3HAAAgLBD8QMQ8uJjY/T45flqmRCrKycVaXdFte9IAAAAYYXiByAstE9L0qOXDtGyjbt0xyuz5RyTuwMAANQXxQ9A2Di+Z4ZuPqOP3igu1T+/XOk7DgAAQNig+AEIK+NP6qGRfdvpD1PnqWjVVt9xAAAAwoLX4mdmT5vZBjObc4B1N5uZM7MMH9kAhKaYGNODFw9WVmqSrplcpC27K31HAgAACHm+j/j9Q9Ko/ReaWSdJZ0ha1dyBAIS+tJbxmjh2qDbtqtT1z81UTS3X+wEAAByK1+LnnPtU0pYDrHpI0q2S+NccgAMa1DFNvz13gD5bvEmPfrDYdxwAAICQ5vuI338ws3MlrXXOFfvOAiC0XXpUJ12Q31GPfrhYHy/c4DsOAABAyAqp4mdmLSX9UtJd9dz+CjObbmbTN27c2LThAIQcM9MfzhuoPlkpuuH5WVq7ba/vSAAAACEppIqfpB6SukkqNrMVkjpKKjKz9gfa2Dn3lHNumHNuWGZmZjPGBBAqWiTEauK4oaqpcbpqcpEqqmt8RwIAAAg5IVX8nHOznXPtnHNdnXNdJa2RlO+cW+c5GoAQ1i0jWQ9clKvi1dt0z9T5vuMAAACEHN/TOTwr6UtJfcxsjZn9xGceAOFr1MBs/eyEbvrnlyv1+qy1vuMAAACElDifL+6cu+w71ndtpigAIsCto/pq1uptuv3l2eqfnapeWSm+IwEAAISEkDrVEwCORHxsjB6/PF/JiXG6ctIM7aqo9h0JAAAgJFD8AESUrNQkPXbZEC3ftFu3vVwi55gOFAAAgOIHIOIc16OtfnFmH00tKdM/vljhOw4AAIB3FD8AEenKE3votH7tdM/U+ZqxcqvvOAAAAF5R/ABEpJgY018uGqzs1km65pkibd5V4TsSAACANxQ/ABErrWW8Jo4dqs27K3X9c7NUU8v1fgAAIDpR/ABEtIEd0vT7cwdo2pJNeuT9Rb7jAAAAeEHxAxDxLjmqsy4a2lGPfrhEHy3c4DsOAABAs6P4AYgKvz9voPplp+rG52dpzdY9vuMAAAA0K4ofgKiQFB+riWPzVVPjdNXkIlVU1/iOBAAA0GwofgCiRteMZP354jyVrNmu30+Z5zsOAABAs6H4AYgqZw5or5+f2F2Tvlql12au9R0HAACgWVD8AESdW87so6O7tdEdr8zWwnU7fccBAABochQ/AFEnLjZGj182RMmJcRo/aYZ2llf5jgQAANCkKH4AolK71CQ9fvkQrdyyR7e9XCLnmNwdAABELoofgKh1bPe2uuXMPnpz9jo9/fkK33EAAACaDMUPQFT7+YnddUb/LN375nxNX7HFdxwAAIAmQfEDENXMTA9clKcO6S109TNF2rSrwnckAACARkfxAxD10lrEa+LYodq2p0rXPzdTNbVc7wcAACILxQ8AJPXPSdXvzxuoz5ds1kPvLfIdBwAAoFFR/AAg6OJhnXTJsE56/KMl+nDBet9xAAAAGg3FDwDq+O25A9Q/O1U3Pl+s1Vv2+I4DAADQKCh+AFBHUnysnhw3VLXO6arJRSqvqvEdCQAA4IhR/ABgP53bttSDFw/W7LXb9bsp83zHAQAAOGIUPwA4gNP7Z+nKk3roma9X6eUZa3zHAQAAOCIUPwA4iF+c0VvHdm+jO1+brQXrdviOAwAA0GAUPwA4iLjYGD162RClJsVr/KQi7Siv8h0JAACgQSh+AHAI7VKS9Pjl+Vq1ZY9ufbFEzjG5OwAACD8UPwD4Dkd3a6PbR/XV23PX6e/TlvuOAwAAcNgofgBQDz89oZtGDWive99aoG9XbPEdBwAA4LBQ/ACgHsxM91+Uq07pLXT15CJt3FnhOxIAAEC9UfwAoJ5Sk+I1cdxQ7Siv0nXPzlR1Ta3vSAAAAPVC8QOAw9AvO1V/OG+Qvly2WQ++t8h3HAAAgHqh+AHAYbpwaEdddnQnPfHxUr0/b73vOAAAAN+J4gcADfCbggEa2CFVN70wS6s27/EdBwAA4JAofgDQAEnxsZo4dqgkafzkGSqvqvGcCAAA4OAofgDQQJ3atNRDlwzW3NIduvuNub7jAAAAHBTFDwCOwMh+Wbrq5B567tvVenH6at9xAAAADojiBwBH6KbTe+u47m31q9fmaF7pDt9xAAAA/gPFDwCOUFxsjB69bIhat4zXVZNnaEd5le9IAAAA/4biBwCNIDMlURMuz9earXv1ixeK5ZzzHQkAAOBfKH4A0EiGdW2j28/qq3fnrdd/f7bMdxwAAIB/ofgBQCP6yYhuOntQe/3p7YX6etlm33EAAAAkUfwAoFGZmf50Qa66tGmpa56dqQ07y31HAgAAoPgBQGNLSYrXE+PytbO8Stc+M1PVNbW+IwEAgChH8QOAJtC3far++L1B+nr5Fv353UW+4wAAgChH8QOAJnJ+fkddfkxnPfnJUr03b73vOAAAIIpR/ACgCd01pr8GdUjTTS/M0srNu33HAQAAUYriBwBNKCk+Vk+MzVeMma6cVKTyqhrfkQAAQBSi+AFAE+vUpqUeuiRP88t26K7X5/iOAwAAohDFDwCawal9s3TNKT31wvQ1euHb1b7jAACAKEPxA4BmcuPpvTW8Z1v9+vU5mlu63XccAAAQRSh+ANBMYmNMj146ROktEzR+UpG2763yHQkAAEQJih8ANKO2rRI1YWy+Srft1S9eLJZzznckAAAQBSh+ANDMhnZJ1y/P7qf35q3XXz9d5jsOAACIAhQ/APDgR8O7anRutu5/e4G+WrbZdxwAABDhKH4A4IGZ6U8X5KprRrKueWamNuwo9x0JAABEMIofAHjSKjFOT44bqt0V1brm2Zmqrqn1HQkAAEQoih8AeNQ7K0X3nj9I3yzfogfeWeg7DgAAiFAUPwDw7LwhHTTu2M7666fL9Pacdb7jAACACETxA4AQ8Osx/ZXXMU23vFis5Zt2+44DAAAiDMUPAEJAYlysJozNV2ysafykGdpbWeM7EgAAiCAUPwAIER3TW+qhSwZr4fqd+vXrc5jcHQAANBqKHwCEkFP6tNO1p/bSSzPW6PlvV/uOAwAAIgTFDwBCzPUje+mEXhm66425mrN2u+84AAAgAlD8ACDExMaYHrl0iNomJ2j85BnavqfKdyQAABDmKH4AEILaJCdowth8rdterptfnKXaWq73AwAADUfxA4AQld85XXee3U/vz9+gJz9d6jsOAAAIYxQ/AAhhPzi+qwrycvTndxbqi6WbfMcBAABhiuIHACHMzHTf+YPULSNZ1z07U+t3lPuOBAAAwhDFDwBCXHJinJ4cN1R7Kmt0zTNFqqqp9R0JAACEGYofAISBXlkpuvf8Qfp2xVbd//YC33EAAECYofgBQJg4d3AH/ddxXfTfny3XW7PLfMcBAABhhOIHAGHkztH9lNeptW55qUTLNu7yHQcAgKizfkd5WP4OpvgBQBhJjIvVE2PzFR9rumpykfZW1viOBABAxNu8q0KTvlqpS5/6Usfe+4EeeGeh70iHLc53AADA4enQuoUeuXSIfvA/3+jO12brLxflycx8xwIAIKJs31uld+euU2FJmT5fskk1tU7dM5N13am9VJCX4zveYaP4AUAYOrF3pq4f2UsPv79Yw7q00eXHdPYdCQCAsLe7olrvz1+vKSVl+mThRlXW1KpjegtdcWJ3FeTmqF92Stj+sZXiBwBh6rpTe6lo1Tbd/cZcDeqQpkEd03xHAgAg7JRX1ejjhRtVWFKqD+avV3lVrbJSE/X947qoIC9HeR3Twrbs1WXOOd8ZGsWwYcPc9OnTfccAgGa1ZXelxjz6mWJiTFOuHaHWLRN8RwIAIORV1dRq2uJNKiwu1bvz1mtXRbXaJCfo7EHtVZCbo6O6tlFMTPiVPTOb4ZwbdqB1HPEDgDDWJjlBT4wbqoue/EI3vVCsv/3XsLD8RQUAQFOrqXX6etlmFZaU6q0567RtT5VSkuJ09qD2GpObo+N7tFVcbOSOfUnxA4AwN7hTa/16TH/d9fpcTfxkqa4+pafvSAAAhITaWqeiVVs1paRMU0rKtGlXhVomxOr0/lkqyM3RCb0zlBgX6ztms6D4AUAE+P6xXTR9xVb95d2FGtyptYb3zPAdCQAAL5xzmrN2hwpLSjWluFSl28uVEBejkX3baUxujk7t204tEqKj7NVF8QOACGBmuvf8QZpXtkPXPTtTU687Qe3TknzHAgCg2Sxct1OFxaUqLCnVys17FBdjOrF3pm4Z1Uen9ctSSlK874heUfwAIEIkJ8bpyXH5Oufxz3X1M0V67opjFR/B1yoAALB8025NCZa9Ret3Kcak43tk6KqTe+jMAe0Z9KwOih8ARJCe7VL0pwtyde2zM3Xvmwt0V0F/35EAAGhUa7ft1ZTiUk0pKdPstdslSUd1Tdfvzh2gswZmKzMl0XPC0ETxA4AIU5CXoxkrt+rpz5draJd0jc7N9h0JAIAjsmFnud4sKVNhSZlmrNwqScrrmKY7z+6n0bnZymndwnPC0EfxA4AI9Muz+6l4zTbd+lKx+manqEdmK9+RAAA4LFt3V+qtOes0paRUXy3brFon9W2folvO7KMxudnq0jbZd8SwwgTuABChyrbv1ehHpymjVYJeu3q4Wibwtz4AQGjbUV6l9+auV2FJqaYt3qTqWqduGckqyMtRQW62emWl+I4Y0pjAHQCiUHZaCz1y6WD919Pf6M5X5+jBi/NkxuTuAIDQsqeyWh/M36DC4lJ9vGijKqtr1aF1C/3khG4qyM3RgJxUfn81Aq/Fz8yeljRG0gbn3MDgsgckFUiqlLRU0o+cc9u8hQSAMHZCr0zdeFpvPfjeIg3tkq5xx3bxHQkAAFVU1+iThRtVWFKm9+et196qGrVLSdTYYzprTG6O8ju3puw1Mt9H/P4h6XFJ/6yz7D1Jdzjnqs3sT5LukHSbh2wAEBGuOaWnilZt1e8K5ym3Y5pyO7b2HQkAEIWqamr1+ZJNmlJSpnfmrtPO8mqlt4zX9/I7qCA3R0d3a6PYGMpeU/Fa/Jxzn5pZ1/2WvVvn7leSLmzWUAAQYWJiTA9dPFhjHpum8ZOKNOXaEUpPZl4jAEDTq6l1+mb5FhWWlOqt2WXauqdKKYlxOnNge43JzdbwnhnMOdtMfB/x+y4/lvS87xAAEO7SkxP0xNh8XfTkl7rxhVl6+gdHKYa/qgIAmoBzTkWrtqmwuFRTZ5dp484KtYiP1Wn9s1SQm60Te2cqKT7Wd8yoE7LFz8zulFQtafIhtrlC0hWS1Llz52ZKBgDhKa9Ta/26oL9+/docTfhoia4d2ct3JABAhHDOaW7pDhWWlGpKcZnWbturhLgYndInUwV5OTq1bztGl/YsJPe+mf1QgUFfRrpDzDfhnHtK0lNSYDqH5kkHAOFr3DGdNWPFFj34/iIN6ZyuEb0yfEcCAISxxet3qrC4VFNKyrRs027FxZhG9MrQTaf31ukDspSaFO87IoJCrviZ2ShJt0o6yTm3x3ceAIgkZqY/nj9I88p26LrnZmrqdSOUndbCdywAQBhZuXm3ppSUqbC4VAvW7ZSZdFz3tvrZid01akB7riMPUV4ncDezZyWdLClD0npJv1FgFM9ESZuDm33lnLvyu56LCdwBoP6Wbtylcx6bpt7tU/T8FccpIY4L6wEAB1e6ba+mlpRpSkmpitdslyQN7ZKugtxsnT0oW+1SkzwnhHToCdy9Fr/GRPEDgMMztaRMVz9TpB8e31V3nzPAdxwAQIjZuLNCb80JHNn7dsVWSdKgDmkqyMvW6NwcdWjNGSOh5lDFL+RO9QQANI/RudmasbKbnv58eeCvtnk5viMBADzbtqdSb89Zp8KSUn25dLNqndQ7q5VuPr23xuTlqFtGsu+IaCCKHwBEsTvO7qviNdt0+8sl6pedqp7tWvmOBABoZjvLq/T+/PUqLC7Tp4s2qrrWqWvblrr6lJ4ak5ujPu1TfEdEI+BUTwCIcuu2l2v0o5+pTXKCXrt6uJIT+ZsgAES6vZU1+nDBBk0pKdWHCzaoorpWOWlJGpOXo4LcHA3skCoz5nsNN5zqCQA4qPZpSXr0siH6/t+/1i9fna2HLxnML3sAiEAV1TX6bNEmFZaU6r1567WnskYZrRJ12dGdNSY3W/md0xUTw+d/pKL4AQA0vGdgzqU/v7tIw7qk6/vHdfUdCQDQCKpravXF0s0qLC7VO3PXaUd5tVq3jNe5gwNH9o7p3laxlL2oQPEDAEiSrjq5p4pWbdPvpszToI6tNbhTa9+RAAANUFvr9O2KLSosKdVbs9dp8+5KtUqM0xkDslSQl6MRPTMUH8s0PtGGa/wAAP+ybU+lxjw2Tc5JU64dwSS8ABAmnHOatXqbCovLNHV2qdbvqFBSfIxG9stSQW6OTu6TqaT4WN8x0cS4xg8AUC+tWyboibH5unDil7rh+Vn6nx8exfUeABCinHOaX7ZThSWlKiwu1Zqte5UQG6OT+mSqIC9HI/u2Y8Au/AvvBADAv8nt2Fq/Oae/7nx1jh77cImuP62X70gAgDqWbNilwuJSTSkp1dKNuxUbYxreM0PXj+ylMwa0V1qLeN8REYIofgCA/3D50Z01Y8VWPfzBIg3u3Fon9c70HQkAotrqLXuCR/bKNL9sh8ykY7q10Y9HdNOoAe3VtlWi74gIcRQ/AMB/MDPd871Bmlu6Qzc8N1NTrjtBHVq38B0LAKLKuu3lmlJSqsKSMhWv3iZJGtK5te4a01+jc7OVlZrkNyDCCoO7AAAOatnGXTrn8c/Vs10rvfDz45QQxyhwANCUNu2q0Ftz1qmwuFTfrtgi56QBOakqyMvR6EHZ6tSmpe+ICGEM7gIAaJDuma3054tydeWkIt0zdZ5+e+5A35EAIOJs31Old+auU2FJqb5Yulk1tU49MpN1w8jeGpOXrR6ZrXxHRASg+AEADmnUwGz9dEQ3/W3acg3t2kbn5OX4jgQAYW93RbXen79ehcWl+mTRRlXVOHVu01JXntRdY3Jz1Ld9iswYVRmNh+IHAPhOt53VV8Vrtun2l0vUr32KemWl+I4EAGGnvKpGHy3YoMKSUn24YIPKq2qVnZakHxzXVQV5OcrtmEbZQ5PhGj8AQL2s31Gu0Y9+ptYtE/T61cOZGwoA6qGyulbTlmxUYXGZ3p27Trsra5TRKkFnD8pWQV6OhnZOZ75UNBqu8QMAHLGs1CQ9etkQjfvb17r9ldl69NLB/GUaAA6guqZWXy3bosLiUr09d522761SalKcxuTmqCAvR8d2b6O4WAbLQvOi+AEA6u34Hhm6+Yw+euCdhRrWJV0/OL6r70gAEBJqa51mrNqqwuJSvTm7TJt2VSo5IVZnDGivgrxsjeiZycjI8IriBwA4LONP6qGilVv1h6nzNKhjmvI7p/uOBABeOOdUsma7CotLNXV2mcq2lysxLkYj+7VTQW6OTunbTknxsb5jApK4xg8A0ADb91RpzOOfqabGacp1J6hNcoLvSADQLJxzWrBuZ2Bi9eIyrdqyR/GxppN6Z6ogL0cj+2WpFddAwxOu8QMANKq0lvGaOHaozp/4ha5/bqb+8aOjFcvgBAAi2LKNu1RYXKbCklIt2bBLsTGm43u01TWn9NSZA9orrWW874jAIVH8AAANMrBDmn57zgDd8cpsPfLBYt10em/fkQCgUa3eskdTZ5epsLhUc0t3yEw6qmsb/f68gTprYHtltEr0HRGoN4ofAKDBLj2qk6av2KrHPlys/M6tdXKfdr4jAcARWb+jXFNLAkf2Zq7aJknK69RavxrdT6Nzs5Wd1sJvQKCBKH4AgAYzM/3hvIGaW7pdNzw/S1OuHaGO6S19xwKAw7Jld6XemhM4svf18i1yTuqXnapbR/XRmEE56tyWzzWEPwZ3AQAcsRWbdqvgsWnqnpmsF648TolxjGIHILRt31uld+eu05SSMk1bskk1tU7dM5NVkJujgrxs9WyX4jsicNgY3AUA0KS6ZiTrgYvydOWkGfrDlPn6/XkDfUcCgP+wp7Ja78/foMLiUn2ycKMqa2rVMb2Frjixuwpyc9QvO0VmDFSFyETxAwA0ilED2+uKE7vrqU+XaVjXdJ07uIPvSACg8qoafbxwowpLSvXB/PUqr6pVVmqixh3bRQV52RrcqTVlD1GB4gcAaDS3ntlHs1Zt0+0vz1a/7FT1zuJUKQDNr6qmVtOWbFJhcanenbteuyqq1SY5QRcO7aiC3Bwd1bWNYpiCBlGGa/wAAI1qw45ynf3oNKW2iNMb14xgImMAzaKm1unrZZtVWFKqt+as07Y9VUpJitOoAe1VkJej43u0VVxsjO+YQJPiGj8AQLNpl5qkxy4borF/+0q3vVyixy8bwmlUAJpEba3TzNVbVVhcpqmzy7RxZ4VaJsTq9P5ZKsjN0Qm9MxhsCgii+AEAGt1xPdrqljP76k9vL9CwLun60fBuviMBiBDOOc1Zu0OFJaWaWlKmtdv2KiEuRqf2aaeCvByd2redWiRQ9oD9UfwAAE3iypO6a8bKrbpn6nzldmytoV3SfUcCEMYWrd+pwuJSFRaXasXmPYqLMZ3YO1O/OLO3TuuXpZSkeN8RgZDGNX4AgCazfW+VCh6bpsrqWk29boTatkr0HQlAGFm+abemFJeqsKRUi9bvUowFzigoyM3RqIHt1bplgu+IQEg51DV+FD8AQJOas3a7zp/4hY7qmq5//vgYxTKSHoBDWLttr6aWlKqwuEyz126XJB3VNV0FeTk6a2C2MlP4AxJwMAzuAgDwZmCHNP3h3IG69eUSPfz+It18Rh/fkQCEmA07y/VmSZkKS8o0Y+VWSVJexzTdeXY/jc7NVk7rFp4TAuGP4gcAaHIXH9VJ01du0WMfLlF+53Sd0red70gAPNu6u1Jvz12nwuJSfbVss2qd1Ld9im45s4/G5GarS9tk3xGBiELxAwA0i9+dO1Bz1u7QDc/P0pRrR6hTm5a+IwFoZjvKq/Te3PUqLCnVtMWbVF3r1C0jWdec0lNj8nLUOyvFd0QgYnGNHwCg2azcvFtjHpumbhnJevHK45hfC4gCeyqr9eGCDSosLtVHCzeqsrpWHVq30Ji8bBXk5mhATipzfQKNhGv8AAAhoUvbZP3lojxd8f9m6HeF83TP9wb5jgSgCVRU1+iThRtVWFKm9+et196qGrVLSdTlR3dWQV6O8ju3puwBzYziBwBoVmcMaK+fn9Rdf/1kmYZ1Tdf3hnT0HQlAI6iqqdUXSzersLhU78xdp53l1UpvGa/v5XdQQW6Oju7WhlF9AY8ofgCAZnfLGX00a9U23fHKbPXPTlOf9lzXA4Sjmlqnb5ZvUWFJqd6es05bdlcqJTFOZw5srzG52RreM0PxsTG+YwIQ1/gBADzZsLNcox+dppTEOL1+zXClJMX7jgSgHpxzKlq1TVNKSjW1pEwbdlaoRXysTuufpYLcbJ3YO1NJ8Vy/C/jANX4AgJDTLiVJj182RJf/7Wvd9nKJJlyezzU/QIhyzmlu6Q4VlpRqSnGZ1m7bq4S4GJ3cO1MFeTka2a+dWibwz0oglPF/KADAm2O6t9WtZ/bRvW8t0NOfr9BPRnTzHQlAHYvX71RhSZmmFJdq2abdiosxjeiVoZtO763TB2QplSP1QNig+AEAvLrixO6asXKr7n1zvvI6pmlY1za+IwFRbeXm3ZpSUqbC4lItWLdTZtJx3dvqZyd216gB7ZWenOA7IoAG4Bo/AIB32/dW6ZzHp6m8qkZTrztBGa0SfUcCokrZ9r2aGix7xWu2S5KGdklXQW62zh6UrXapSZ4TAqiPQ13jR/EDAISEeaU79L0nPtfQLun6fz85hmHfgSa2cWeF3poTKHvfrtgqSRrUIU1jcrM1OjdbHdNbek4I4HAxuAsAIOT1z0nVH84bqFteKtGD7y3ULWf29R0JiDjb9lTqnbnrVFhcpi+WblKtk3q1a6WbT++tMXk56paR7DsigCZC8QMAhIyLhnXSjJVbNeGjpcrvnK6R/bJ8RwLC3q6Kar03L1D2Plu8UVU1Tl3attRVJ/dUQV4O82gCUYLiBwAIKXefM0Cz127Xjc/P0tTrTlCnNpxuBhyuvZU1+mjhBhUWl+rDBRtUUV2rnLQk/Wh4NxXk5mhgh1SmTwGiDMUPABBSkuJjNXHsUI157DONnzxDL115PJNBA/VQUV2jzxZtUmFJqd6ft167K2uU0SpRlx3dWWNys5XfOV0xXDsLRC2KHwAg5HRu21IPXjxYP/3ndP22cJ7uPX+Q70hASKquqdUXSzdrSkmp3p6zTjvKq9W6ZbzOGZyjgtwcHdO9LQMlAZBE8QMAhKjT+mdp/Mk9NPHjpRrWJV0XDO3oOxIQEmprnb5dsUWFJaV6a/Y6bd5dqVaJcTqjf5YK8nI0vGeGEuJifMcEEGIofgCAkHXz6b01a9U23fnabA3okKq+7VN9RwK8cM6peM12FRaXampJmdbtKFdSfIxG9stSQW6OTu6TySnRAA6JefwAACFt484KjX70MyUnxun1a4YrNSnedySgWTjnNL9spwpLSjWlpFSrt+xVQmyMTuqTqTG52TqtX5aSE/kbPoD/wzx+AICwlZmSqMcvz9dl//2Vbn2xRBPH5TMaISLakg27NKWkVIXFpVq6cbdiY0zDe2boulN76YwB7ZXWgj9+ADh8FD8AQMg7ulsb3T6qr+55c77+Pm25fnpCd9+RgEa1esseFZaUqrC4TPPLdshMOqZbG/1oeDedNbC92rZK9B0RQJij+AEAwsJPT+imGSu36t63Fii3Y2sd3a2N70jAEVm3vVxTZ5epsLhUs1ZvkyQN6dxad43pr9G52cpKTfIbEEBE4Ro/AEDY2FFepXMf/1y7K6o15boRapfCP4wRXjbvqtCbc9apsLhU367YIuek/tmpKsjL0ZjcbHVq09J3RABhjGv8AAARITUpXhPH5eu8CZ/rumdnatJPjlFcLMPWI7Rt31uld+YGyt4XSzerptapR2aybhjZW2PystUjs5XviACiAMUPABBW+rZP1T3nDdLNLxbrL+8t0m2j+vqOBPyH3RXVen/+ehUWl+qTRRtVVePUuU1LXXlSd43JzVHf9ikMUgSgWVH8AABh54KhHTV95VZN/Hip8jun6/T+Wb4jASqvqtFHCzZoSkmZPliwXuVVtWqfmqQfHNdVBXk5yu2YRtkD4A3FDwAQln5T0F+z127TTS/M0tRrT1DntlwbheZXWV2raUs2qrC4TO/OXafdlTXKaJWgi4Z2UkFejoZ1SVdMDGUPgH8UPwBAWEqKj9XEsUM15rFpGj95hl4ef7yS4mN9x0IUqK6p1dfLt6iwuFRvzVmn7XurlJoUpzG5OSrIy9Gx3dtw7SmAkEPxAwCErU5tWuqhS/L0439M191vzNV9F+T6joQIVVvrNGPVVhUWl+rN2WXatKtSyQmxOmNAe43JzdYJvTKVEEfZAxC6KH4AgLB2at8sXX1KD034aKmGdknXRcM6+Y6ECOGc0+y121VYXKopJWUq216uxLgYjezXTgW5OTqlbzuOMgMIGxQ/AEDYu+n0Ppq5apt+9docDchJU/+cVN+REKacc1q4fqcKi0tVWFymVVv2KD7WdFLvTN02qq9O65+lVon88wlA+GECdwBARNi0q0KjH/1MLeJj9ca1I5SaFO87EsLIso27NKWkTIXFpVq8YZdiTBreM0MFuTk6c0B7pbXk/QQg9DGBOwAg4mW0StSEy/N16VNf6RcvFOuv3x/K0Pk4pDVb9/yr7M0t3SFJOrpbG/3+3AE6a1C2Mlolek4IAI2H4gcAiBjDurbRHWf30++nzNNTny7Tz0/q4TsSQsyGHeWaOjtQ9opWbZMk5XVqrV+N7qfRudnKTmvhNyAANBGKHwAgovx4eFcVrdyq+99ZqMGdWuuY7m19R4JnW3ZX6q05gbL39fItck7ql52qW0f10ZhBOcwBCSAqUPwAABHFzHTfBYM0v2yHrnl2pqZeO0LtUpN8x0Iz21FepXfnrldhcammLdmkmlqn7pnJuu7UXirIy1bPdim+IwJAs6L4AQAiTkpSvCaOG6rzJnyua56dqWd+egwTakeBPZXVen/+BhUWl+qThRtVWVOrjuktdMWJ3TUmN1v9s1O57hNA1KL4AQAiUp/2Kfrj+QN14/PFeuDdhbrjrH6+I6EJlFfV6OOFGzWlpFQfzN+gvVU1apeSqHHHdlFBXrYGd2pN2QMAUfwAABHse0M6avqKrfrrJ8s0tHO6zhjQ3nckNIKqmlpNW7JJhcWlem/ueu2sqFab5ARdMLSDxuTm6KiubRQbQ9kDgLoofgCAiHZXQX/NXrtdN79YrCntU9SlbbLvSGiAmlqnr5dvVmFxmd6aU6Zte6qUkhSnUQPbqyAvR8f3aMvpvABwCBQ/AEBES4yL1YTL8zXmsWm6clKRXr3qeCXFx/qOhXqorXWauXqrCovLNHV2mTburFDLhFid3j9LBbk5OqF3hhLj+G8JAPVB8QMARLxObVrq4UsG60f/+FZ3vT5H91+Y5zsSDsI5pzlrd2hKSammlJRp7ba9SoiL0al92qkgL0en9m2nFgmUPQA4XBQ/AEBUOKVvO117ak899uESDevSRhcf1cl3JNSxaP1OFRaXqrC4VCs271FcjOnE3pm6+YzeOr1/llKS4n1HBICwRvEDAESNG07rrZmrtunXr89R/5xUDeyQ5jtSVFuxabemlJSqsLhMC9fvVIxJx/VoqytP6qEzB7RXenKC74gAEDHMOec7Q6MYNmyYmz59uu8YAIAQt3lXhUY/Ok0JcTEqvHaE0lpwJKk5rd22V1ODZW/22u2SpKO6pqsgL0dnDcxWZkqi54QAEL7MbIZzbtiB1nHEDwAQVdq2StSEsfm65K9f6uYXivXU94cqhqH/m9SGneV6a/Y6FRaXavrKrZKk3I5puvPsfhqdm62c1i08JwSAyEfxAwBEnaFd0nXn6H76beE8/fXTZRp/cg/fkSLO1t2VentuoOx9tWyzap3Ut32Kbjmzj0YPylbXDKbVAIDmRPEDAESlHx7fVdNXbtUD7yzQ4E6tdVyPtr4jhb2d5VV6d+56TSkp1WeLN6m61qlbRrKuOaWnxuTlqHdWiu+IABC1KH4AgKhkZvrTBblaULZD1z47U29eN0LtUpN8xwo7eytr9MGC9SosLtVHCzeqsrpWHVq30E9O6KaC3BwNyEmVGafSAoBvFD8AQNRqlRinieOG6tzHP9c1z8zU5J8do/jYGN+xQl5FdY0+XbRJhcWlen/+eu2prFFmSqIuP7qzCvJylN+5NWUPAEIMxQ8AENV6Z6XovgsG6frnZumBdxbql2f38x0pJFXV1OqLpZtVWFyqd+au087yaqW3jNd5QzqoIDdHR3dro1gGyQGAkEXxAwBEvXMHd9D0FVv11KfLlN85XaMGtvcdKSTU1Dp9s3yLppSU6q0567Rld6VSEuN0xoD2KsjL1vCeGRwhBYAwQfEDAEDSr8b0U8na7brlxWL1aZ+iblE66qRzTjNXb1NhcammlpRpw84KtYiP1Wn9szQmN1sn9c5UUnys75gAgMPktfiZ2dOSxkja4JwbGFzWRtLzkrpKWiHpYufcVl8ZAQDRITEuVhMuH6Ixj03T+Ekz9OpVw9UiIToKjnNOc0t3aEpJmQqLS7V2214lxMXo5N6ZKsjL0ch+7dQygb8VA0A4M+ecvxc3O1HSLkn/rFP87pe0xTl3n5ndLindOXfbdz3XsGHD3PTp05s2MAAg4n28cIN+9I9vdUF+Rz1wYW5ED1KyZMNOvVFcpinFpVq2abfiYkwjemWoIDdHpw/IUmpSvO+IAIDDYGYznHPDDrTO65/vnHOfmlnX/RafK+nk4Pf/K+ljSd9Z/AAAaAwn92mna0/tpUc/WKxhXdJ16dGdfUdqVKs271FhSakKi0u1YN1OmUnHdmurn57QXaMGtleb5ATfEQEATSAUz9vIcs6VBb9fJynLZxgAQPS5fmQvzVy1VXe9MVcDO6RpYIc035GOSNn2vZoaPI2zeM12SdLQLum6u6C/zh6UzfyFABAFvJ7qKUnBI35T6pzquc0517rO+q3OufSDPPYKSVdIUufOnYeuXLmy6QMDAKLClt2VGvPoZ4qJMU299gSltQyv0x437qzQW3PKNKW4TN+s2CJJGtghVQW5ORqdm62O6S09JwQANLZDneoZisVvoaSTnXNlZpYt6WPnXJ/veh6u8QMANLaZq7bq4r9+qRN7Zeq//2uYYkJ8nrpteyr1ztx1Kiwu0xdLN6nWSb3atdI5eTkak5cTtSOVAkC0CNlr/A7iDUk/kHRf8PZ1v3EAANFqSOd0/Wp0f/3mjbma+MlSXX1KT9+R/sOuimq9N2+dphSX6dPFG1VV49SlbUtddXJPFeTlqE/7FN8RAQAhwPd0Ds8qMJBLhpmtkfQbBQrfC2b2E0krJV3sLyEAINr913FdNH3lVv3l3YUa0rm1ju+R4TuSyqtq9OGCDSosLtWHCzaoorpWOWlJ+tHwbirIzdHADqkRPRopAODweT/Vs7FwqicAoKnsrqjWuRM+17Y9lZpy7Qlqn9b8g6FUVtfqs8UbVVhcqvfmrdfuyhpltErQ6EHZKsjLUX7n9JA/FRUA0LTC7VRPAABCSnJinJ4cl69zHv9c1zxTpGevOFbxsTFN/rrVNbX6ctlmFRaX6u0567SjvFppLeJ1zuAcFeTm6JjubRVL2QMA1APFDwCAeujZLkX3XZCr656dqT+9tUC/GtO/SV6nttbp2xVbVFhSqrdmr9Pm3ZVqlRinM/pnqSAvR8N7ZighrulLJwAgslD8AACop3PycjRjxRb9bdpyDe2SrrMGZTfK8zrnVLxmuwqLSzW1pEzrdpQrKT5GI/tlqSA3Ryf3yVRSfGyjvBYAIDpR/AAAOAx3ju6v4jXbdctLJerTPkXdM1s16Hmcc5pftlNTSkpVWFKq1Vv2KiE2Rif2ztQdZ/fVaf2ylJzIr2kAQONgcBcAAA7T2m17NebRz5SVmqRXrxquFgn1Pxq3dOMuFRaXqrC4VEs37lZsjGl4zwwV5GbrjAHtldYivCaKBwCEDgZ3AQCgEXVo3UKPXDpEP/ifb3Tnq7P1l4vzDjl9wuote1RYUqopxWWaV7ZDZtLRXdvoR8O76ayB7dW2VWIzpgcARCOKHwAADXBi70zdMLK3Hnp/kYZ2TdfYY7r82/p128s1dXaZCotLNWv1NknSkM6tddeY/hqdm62s1OafEgIAEL0ofgAANNC1p/ZU0aqt+u0b8zSoQ5o6tG6hN+es05TiUn2zYouck/pnp+q2UX01Jjdbndq09B0ZABCluMYPAIAjsHV3pcY8Nk079lZpT1WNamqdemQm65y8DhqTl60eDRz8BQCAw8U1fgAANJH05ARNHJev3xbO0zHd2qggL0d926cc8po/AACaG8UPAIAjlNuxtV4ef7zvGAAAHFSM7wAAAAAAgKZF8QMAAACACEfxAwAAAIAIR/EDAAAAgAhH8QMAAACACEfxAwAAAIAIR/EDAAAAgAhH8QMAAACACEfxAwAAAIAIR/EDAAAAgAhH8QMAAACACEfxAwAAAIAIR/EDAAAAgAhH8QMAAACACEfxAwAAAIAIR/EDAAAAgAhH8QMAAACACEfxAwAAAIAIR/EDAAAAgAhH8QMAAACACEfxAwAAAIAIR/EDAAAAgAhH8QMAAACACGfOOd8ZGoWZbZS00neOA8iQtMl3iCjFvveHfe8P+94f9r1f7H9/2Pf+sO/9CdV938U5l3mgFRFT/EKVmU13zg3znSMase/9Yd/7w773h33vF/vfH/a9P+x7f8Jx33OqJwAAAABEOIofAAAAAEQ4il/Te8p3gCjGvveHfe8P+94f9r1f7H9/2Pf+sO/9Cbt9zzV+AAAAABDhOOIHAAAAABGO4ncEzGyUmS00syVmdvsB1iea2fPB9V+bWdc66+4ILl9oZmc2a/AIUI99f5OZzTOzEjP7wMy61FlXY2azgl9vNG/y8FePff9DM9tYZx//tM66H5jZ4uDXD5o3efirx75/qM5+X2Rm2+qs431/BMzsaTPbYGZzDrLezOzR4H+bEjPLr7OO9/0RqMe+Hxvc57PN7Aszy6uzbkVw+Swzm958qSNDPfb9yWa2vc5ny1111h3y8wqHVo99f0ud/T4n+BnfJriO9/0RMLNOZvZR8N+Rc83s+gNsE56f+c45vhrwJSlW0lJJ3SUlSCqW1H+/ba6S9GTw+0slPR/8vn9w+0RJ3YLPE+v7ZwqXr3ru+1MktQx+P37fvg/e3+X7ZwjXr3ru+x9KevwAj20jaVnwNj34fbrvnylcvuqz7/fb/lpJT9e5z/v+yPb/iZLyJc05yPqzJb0lySQdK+nr4HLe902/74/ft08lnbVv3wfvr5CU4ftnCNeveuz7kyVNOcDyw/q84uvw9/1+2xZI+rDOfd73R7bvsyXlB79PkbToAP/WCcvPfI74NdzRkpY455Y55yolPSfp3P22OVfS/wa/f0nSSDOz4PLnnHMVzrnlkpYEnw/185373jn3kXNuT/DuV5I6NnPGSFWf9/3BnCnpPefcFufcVknvSRrVRDkj0eHu+8skPdssyaKAc+5TSVsOscm5kv7pAr6S1NrMssX7/oh91753zn0R3LcSn/eNqh7v+4M5kt8V0GHvez7vG5Fzrsw5VxT8fqek+ZI67LdZWH7mU/waroOk1XXur9F/vin+tY1zrlrSdklt6/lYHNzh7r+fKPBXmX2SzGy6mX1lZuc1Qb5IVt99f0Hw1IeXzKzTYT4WB1bv/Rc8tbmbpA/rLOZ937QO9t+H933z2v/z3kl618xmmNkVnjJFuuPMrNjM3jKzAcFlvO+biZm1VKBYvFxnMe/7RmKBy7SGSPp6v1Vh+Zkf5zsA0JTMbJykYZJOqrO4i3NurZl1l/Shmc12zi31kzAiFUp61jlXYWY/V+Co96meM0WbSyW95JyrqbOM9z0impmdokDxG1Fn8Yjg+76dpPfMbEHwSAoaR5ECny27zOxsSa9J6uU3UtQpkPS5c67u0UHe943AzFopUKhvcM7t8J2nMXDEr+HWSupU537H4LIDbmNmcZLSJG2u52NxcPXaf2Z2mqQ7JZ3jnKvYt9w5tzZ4u0zSxwr8JQf185373jm3uc7+/pukofV9LA7pcPbfpdrvtB/e903uYP99eN83AzPLVeDz5lzn3OZ9y+u87zdIelVcVtGonHM7nHO7gt+/KSnezDLE+745Herznvd9A5lZvAKlb7Jz7pUDbBKWn/kUv4b7VlIvM+tmZgkK/I+3/0h5b0jaN5rPhQpceOuCyy+1wKif3RT469g3zZQ7EnznvjezIZL+qkDp21BnebqZJQa/z5A0XNK8Zkse/uqz77Pr3D1HgXPjJekdSWcE/xukSzojuAz1U5/PHJlZXwUuKP+yzjLe903vDUn/FRzp7VhJ251zZeJ93+TMrLOkVyR93zm3qM7yZDNL2fe9Avv+gCMkomHMrH1w7AKZ2dEK/Ltys+r5eYUjY2ZpCpzR9HqdZbzvj1DwPf13SfOdcw8eZLOw/MznVM8Gcs5Vm9k1CvzHjFVg9Ly5ZvY7SdOdc28o8Kb5f2a2RIELdC8NPnaumb2gwD+8qiVdvd8pWTiEeu77ByS1kvRi8HfSKufcOZL6SfqrmdUq8AvqPucc/wCup3ru++vM7BwF3ttbFBjlU865LWb2ewX+QSBJv9vv1BQcQj33vRT4nHku+EemfXjfHyEze1aBEQwzzGyNpN9Iipck59yTkt5UYJS3JZL2SPpRcB3v+yNUj31/lwLXzz8R/Lyvds4Nk5Ql6dXgsjhJzzjn3m72HyCM1WPfXyhpvJlVS9or6dLgZ88BP688/Ahhqx77XpK+J+ld59zuOg/lfX/khkv6vqTZZjYruOyXkjpL4f2Zb//+bwMAAAAAQKThVE8AAAAAiHAUPwAAAACIcBQ/AAAAAIhwFD8AAAAAiHAUPwAAAACIcBQ/AABCiJm54NfJvrMAACIHxQ8AENLM7O46Zeg7v3znBQAgFDGBOwAgnKz3HQAAgHBE8QMAhA3nXHvfGQAACEec6gkAAAAAEY7iBwCIWGa2Injt3w/NLMXM7jWzhWa218w2mdlrZnbMdzxHrJn92Mw+DD6mwszWmtmL9RmAxcw6mdn9ZjbLzLYHX3upmb1uZv9lZkmHeGyKmf3BzBYEH7fZzKYcKrOZpZvZ78ysyMx2mFmlma0zsxIze9LMRn5XZgBA5DHnuA4eABC6zOxuSb+RJOecHeZjV0jqIukmST+X1EdSpaRySanBzWol/cw59/QBHp8m6TVJJwcX1UjaKSlN0r4sf3bO3XKQ1/++pKck7St3lXUev+9yiyHOuVl1HrPvF/Plkn4nqWcwb62klnWep8A59+5+r9dR0ueSOtf52bYHf9bY4LJPnHMnCwAQVTjiBwCIBr+R1E7SxZKSnXNpkvpL+kSB34V/NbP8Azzu7wqUvkpJ10lKdc6lS8qRtK8o/sLMrtz/gWY2WtL/KlD6Ppd0gqQWzrkMScnB+/8dfO4DmRBcd2pw+1aSjpa0UFKCpKfMbP/f43crUPpWSDpNUoJzro2kREldJY2X9NVBXg8AEME44gcACGl1j/jpu0f1fN45d32dx65Q4IifJJ3mnPtgv+duIalYUi9JbzrnRtdZd4z+ryT93Dn31AGyvSTpAkmbJHVyzpUHl8dJWiSpm6RpkkY65w5W8PZ/zn2/mDdKGuic27Df+kGSSoJ3RzjnPq+zbp6kfpIud849W5/XAwBEB474AQDCSdZ3fKUd5HGf71/6JMk5t1fSA8G7o4Kndu5zSfB2jaS/HeR5fx28zZB0ep3lpyhQ+iTpxvqWvv08tX/pC2aeLWl58G7ufqu3BW+zG/B6AIAIRvEDAIQN55x9x9cPD/LQDw/xtPvWxUiqe7rnsODtR8652oPkmS9p7X7bS9Lxwdt1zrnph3jtQ/n6EOtKg7dt9ls+JXh7n5k9ZWajzCxVAICoR/EDAESDtfVc1+4A3x/qsVLgiOD+j9033+DK7452UDsPsa46eBu/3/IHJL0QXP4zSW9J2mZms83sATPrcwR5AABhjOIHAEDj83IBvXOuyjl3iaTBCowI+qGkPZIGSvqFpLlmdrOPbAAAvyh+AIBo0KGe6zYc4PuO3/Hc+9bXfey64G0XeeCcK3bO/cY5N1JSawVG+PxUgSkdHjCzPB+5AAD+UPwAANHglHqsq5U0s87yfdfmnXKAaRMkSWbWV/9XHL+ts+qL4G17Mxsmj5xz1cGBbUZLqlBg/sHTfGYCADQ/ih8AIBqMMLOT919oZkmS9p36+I5zblud1c8FbztI+ulBnvd3wdtNkt6vs/wjScuC3z9kZgmHH/nwmVniIVZXKDABvRQouQCAKELxAwBEg+2SXjazC4Nz7O07WjdVUl8FCtFddR/gnPtG0svBu4+Z2TVm1jL42PZm9t+SLgqu//W+OfyCj62RdI0C1/qNkPSBmY3Yd+TQzBLM7GQzm2Rm/Rvx51xpZvea2bF1S6CZ9ZQ0WVJLBUrfO434mgCAMBDnOwAAAPVlZuu+eyud75z7Yr9lv5X0c0kvSqows3L935x/TtL4g0y78BMF5ug7SdJjChy926nAdXMW3ObPzrkn93+gc+4tM/uhpKcUKH+fBV97V/C19/0O/nM9fqb6ypJ0e/Cr1sy2S2ohKWlfLEk3O+fmNeJrAgDCAMUPABBOsuqxzYFOq9wq6WhJd0i6QFInSVskfS7pXufclwd6IufcdjMbKekHkr4vKU9SKwUGb/lC0uPOuY8PFsQ5908z+1TS9ZLOUGCwlxYKTPMwW4EjivPr8TPV1xkKXLM4QlJn/d/+WqJA8ZzgnJvRiK8HAAgT5pyXEacBAGhyZrZCgbL1I+fcP/ymAQDAH67xAwAAAIAIR/EDAAAAgAhH8QMAAACACEfxAwAAAIAIx+AuAAAAABDhOOIHAAAAABGO4gcAAAAAEY7iBwAAAAARjuIHAAAAABGO4gcAAAAAEY7iBwAAAAAR7v8DGigX4i4a1WsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "760be2a9ecf44bc7b6365e7ce9975bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f581af61cb7426795b8eea5b260a784",
              "IPY_MODEL_963eb22ee09042199c260ef4b0f48e60",
              "IPY_MODEL_b7b5ce6010d74d05bef38422e2b1b70a"
            ],
            "layout": "IPY_MODEL_0486528000f54b8c8443ce2e93bd975f"
          }
        },
        "8f581af61cb7426795b8eea5b260a784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c35da0eafd746839e08a5b0b3ac8931",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd08d79b82f46e8b39c255c270cc2b7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "963eb22ee09042199c260ef4b0f48e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c47383bc49743ceb2e176ccbcee4743",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71a1420175ec4df4bcfe87b300083701",
            "value": 570
          }
        },
        "b7b5ce6010d74d05bef38422e2b1b70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1e42f2d0ee469eb3e4efc752bfeb17",
            "placeholder": "​",
            "style": "IPY_MODEL_759366c0c05d44ab88c42bde7dd735dc",
            "value": " 570/570 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "0486528000f54b8c8443ce2e93bd975f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c35da0eafd746839e08a5b0b3ac8931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd08d79b82f46e8b39c255c270cc2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c47383bc49743ceb2e176ccbcee4743": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a1420175ec4df4bcfe87b300083701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b1e42f2d0ee469eb3e4efc752bfeb17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "759366c0c05d44ab88c42bde7dd735dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d7a38e96ddc418a8421dbe88a3ab824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb433871d0084166aace3b9685223c13",
              "IPY_MODEL_1436916ecc294d4fb92f523e78802f1d",
              "IPY_MODEL_6381750f0a014a6698a78d6cd9a711bb"
            ],
            "layout": "IPY_MODEL_ba09a27a2ccf4cf097601ae469707533"
          }
        },
        "cb433871d0084166aace3b9685223c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882e72ca596b429aab6be377ce3b297a",
            "placeholder": "​",
            "style": "IPY_MODEL_7c5ebaac663e43aa9a2dd01ce9bc7134",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "1436916ecc294d4fb92f523e78802f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6934d6a00554165bce353dbc07c9d70",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1efc6ca7c954007801b31948fa62757",
            "value": 440473133
          }
        },
        "6381750f0a014a6698a78d6cd9a711bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0887256920d04d058fc1bce184b0e93e",
            "placeholder": "​",
            "style": "IPY_MODEL_86fa42e6f985445ea5e41cabc0aae115",
            "value": " 440M/440M [00:02&lt;00:00, 195MB/s]"
          }
        },
        "ba09a27a2ccf4cf097601ae469707533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882e72ca596b429aab6be377ce3b297a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5ebaac663e43aa9a2dd01ce9bc7134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6934d6a00554165bce353dbc07c9d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1efc6ca7c954007801b31948fa62757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0887256920d04d058fc1bce184b0e93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86fa42e6f985445ea5e41cabc0aae115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "278bdbef2ae64e028351f2c61c5dd7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0b31f7474c942e7bc98ddc342afdeee",
              "IPY_MODEL_16df24f7f5484706b95fe4fe32ec3660",
              "IPY_MODEL_d3afa539e73f4b14b2cd5b0d15d818a2"
            ],
            "layout": "IPY_MODEL_84503ea4f07f4695a8069ca5f3ec088e"
          }
        },
        "b0b31f7474c942e7bc98ddc342afdeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d9650b34ae4c9593e6f8d381fad262",
            "placeholder": "​",
            "style": "IPY_MODEL_c568e90e4de54541aebdc374ad9d4f83",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "16df24f7f5484706b95fe4fe32ec3660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351e86ff07b342968725182be74563e3",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daf3096737614cb3995dea395aaf2c01",
            "value": 231508
          }
        },
        "d3afa539e73f4b14b2cd5b0d15d818a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcfc2545dced46c3b4e821ff8c0b29b9",
            "placeholder": "​",
            "style": "IPY_MODEL_191bf5f5ac7d4868afd19173072fb1b2",
            "value": " 232k/232k [00:00&lt;00:00, 2.59MB/s]"
          }
        },
        "84503ea4f07f4695a8069ca5f3ec088e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d9650b34ae4c9593e6f8d381fad262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c568e90e4de54541aebdc374ad9d4f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "351e86ff07b342968725182be74563e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf3096737614cb3995dea395aaf2c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcfc2545dced46c3b4e821ff8c0b29b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191bf5f5ac7d4868afd19173072fb1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0046c4a1d7ef44c68db074d889e5bf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e0c3245c7fe4775bdd4ea27c9a1e8e9",
              "IPY_MODEL_2cc43f42fc5b4bffb91b575737808269",
              "IPY_MODEL_f09aa5759931431e9bf067dda82a36a4"
            ],
            "layout": "IPY_MODEL_fad86784d5974c458fc28c33c892154b"
          }
        },
        "8e0c3245c7fe4775bdd4ea27c9a1e8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c59b0c869d459a98c4b6a292b7f29c",
            "placeholder": "​",
            "style": "IPY_MODEL_946ebdd31d7d4607bc8ef4e6e2f4dfd0",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "2cc43f42fc5b4bffb91b575737808269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_222f16dd891a4d139aab0908bdb9b80c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45368e31d10542bfbe0fa08c6bc02481",
            "value": 28
          }
        },
        "f09aa5759931431e9bf067dda82a36a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_544a2794ed5d4b438425b1d62dcb7b56",
            "placeholder": "​",
            "style": "IPY_MODEL_31155667eb05426889aada48c1206fe9",
            "value": " 28.0/28.0 [00:00&lt;00:00, 885B/s]"
          }
        },
        "fad86784d5974c458fc28c33c892154b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81c59b0c869d459a98c4b6a292b7f29c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946ebdd31d7d4607bc8ef4e6e2f4dfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "222f16dd891a4d139aab0908bdb9b80c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45368e31d10542bfbe0fa08c6bc02481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "544a2794ed5d4b438425b1d62dcb7b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31155667eb05426889aada48c1206fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}